import asyncio
import logging
import queue
import threading
from typing import Any, Generator, Callable, Awaitable
from langchain_core.callbacks import AsyncCallbackHandler
import re
import json

logger = logging.getLogger(__name__)

def _parse_document_citations(text: str) -> str:
    document_pattern = r'\[ë¬¸ì„œ (\d+)\]\(ê´€ë ¨ë„: ([\d.]+)\)\n\[íŒŒì¼ëª…\] ([^\n]+)\n\[íŒŒì¼ê²½ë¡œ\] ([^\n]+)\n\[í˜ì´ì§€ë²ˆí˜¸\] ([^\n]+)\n\[ë¬¸ì¥ì‹œì‘ì¤„\] ([^\n]+)\n\[ë¬¸ì¥ì¢…ë£Œì¤„\] ([^\n]+)'

    matches = re.findall(document_pattern, text)

    if matches:
        citations = []
        for match in matches:
            doc_num, score, file_name, file_path, page_num, line_start, line_end = match

            citation = {
                "document_number": int(doc_num.strip()) if doc_num.strip().isdigit() else doc_num.strip(),
                "relevance_score": float(score.strip()) if score.strip().replace('.', '', 1).isdigit() else score.strip(),
                "file_name": file_name.strip(),
                "file_path": file_path.strip(),
                "page_number": int(page_num.strip()) if page_num.strip().isdigit() else page_num.strip(),
                "line_start": int(line_start.strip()) if line_start.strip().isdigit() else line_start.strip(),
                "line_end": int(line_end.strip()) if line_end.strip().isdigit() else line_end.strip()
            }

            cite_json = json.dumps(citation, ensure_ascii=False)
            escaped_cite_json = cite_json.replace('\"', '"')
            escaped_cite_json = escaped_cite_json.replace('\\"', '"')
            citations.append(f"[Tool_Cite. {escaped_cite_json}]")

        # ì¸ìš© ì •ë³´ë§Œ ë°˜í™˜ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
        return "\n".join(citations)

    # ë¬¸ì„œ ì¸ìš© íŒ¨í„´ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    return ""

class EnhancedAgentStreamingHandler(AsyncCallbackHandler):
    def __init__(self):
        self.token_queue = queue.Queue()
        self.is_done = False
        self.current_step = 0
        self.tool_outputs = []
        self.streamed_tokens = []

    def put_token(self, token):
        if not self.is_done and token:
            self.token_queue.put(('token', str(token)))

    def put_status(self, status):
        if not self.is_done:
            self.token_queue.put(('status', status))

    def finish(self):
        self.is_done = True
        self.token_queue.put(('done', None))

    def put_error(self, error):
        self.is_done = True
        self.token_queue.put(('error', error))

    async def on_llm_start(self, serialized, prompts, **kwargs) -> None:
        """LLM í˜¸ì¶œ ì‹œì‘ ì‹œ"""
        self.current_step += 1
        if self.current_step > 1:
            pass
            # self.put_status(f"\nğŸ’­ ë‹¨ê³„ {self.current_step}: ë‹µë³€ ìƒì„± ì¤‘...\n")

    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        """LLMì´ ìƒˆ í† í°ì„ ìƒì„±í•  ë•Œ í˜¸ì¶œ (OpenAI/Claude ëª¨ë‘ ì§€ì›)"""
        if not token:
            return

        # Claude ëª¨ë¸ì˜ ê²½ìš° í† í°ì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìŒ
        if isinstance(token, list):
            for item in token:
                if isinstance(item, dict) and item.get('type') == 'text' and 'text' in item:
                    text_content = item['text']
                    if text_content:
                        self.streamed_tokens.append(text_content)
                        self.put_token(text_content)
            return

        # Claude ëª¨ë¸ì˜ ê²½ìš° í† í°ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìŒ
        if isinstance(token, dict):
            # text íƒ€ì…ì˜ ì²­í¬ë§Œ ì¶”ì¶œ
            if token.get('type') == 'text' and 'text' in token:
                text_content = token['text']
                if text_content:
                    self.streamed_tokens.append(text_content)
                    self.put_token(text_content)
            # tool_useë‚˜ ë‹¤ë¥¸ íƒ€ì…ì€ ë¬´ì‹œ
            return

        # OpenAI ë“± ë¬¸ìì—´ë¡œ ì˜¤ëŠ” ê²½ìš°
        if isinstance(token, str):
            self.streamed_tokens.append(token)
            self.put_token(token)

    async def on_agent_action(self, action, **kwargs) -> None:
        """Agentê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ë•Œ í˜¸ì¶œ"""
        pass

    async def on_tool_start(self, serialized, input_str, **kwargs) -> None:
        """ë„êµ¬ ì‹¤í–‰ ì‹œì‘ ì‹œ"""
        pass

    async def on_tool_end(self, output, **kwargs) -> None:
        """ë„êµ¬ ì‹¤í–‰ì´ ì™„ë£Œë  ë•Œ í˜¸ì¶œ"""
        pass

    async def on_tool_error(self, error, **kwargs) -> None:
        self.put_status(f"âŒ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(error)}\n")

    async def on_agent_finish(self, finish, **kwargs) -> None:
        pass

    # LangGraph ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ ë©”ì„œë“œ
    async def on_chain_start(self, serialized, inputs, **kwargs) -> None:
        """Chain ì‹œì‘ ì‹œ í˜¸ì¶œ (LangGraph ë…¸ë“œ ì‹¤í–‰ ì‹œì‘)"""
        pass

    async def on_chain_end(self, outputs, **kwargs) -> None:
        """Chain ì¢…ë£Œ ì‹œ í˜¸ì¶œ (LangGraph ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ)"""
        pass

    async def on_chain_error(self, error, **kwargs) -> None:
        """Chain ì˜¤ë¥˜ ì‹œ í˜¸ì¶œ"""
        self.put_error(error)

class EnhancedAgentStreamingHandlerWithToolOutput(AsyncCallbackHandler):
    def __init__(self):
        self.token_queue = queue.Queue()
        self.is_done = False
        self.current_step = 0
        self.tool_outputs = []
        self.streamed_tokens = []
        self.tool_logs = []

    def put_token(self, token):
        if not self.is_done and token:
            self.token_queue.put(('token', str(token)))

    def put_status(self, status):
        if not self.is_done:
            self.token_queue.put(('status', status))

    def finish(self):
        self.is_done = True
        self.token_queue.put(('done', None))

    def put_error(self, error):
        self.is_done = True
        self.token_queue.put(('error', error))

    async def on_llm_start(self, serialized, prompts, **kwargs) -> None:
        """LLM í˜¸ì¶œ ì‹œì‘ ì‹œ"""
        self.current_step += 1
        if self.current_step > 1:
            pass
            # self.put_status(f"\nğŸ’­ ë‹¨ê³„ {self.current_step}: ë‹µë³€ ìƒì„± ì¤‘...\n")

    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        """LLMì´ ìƒˆ í† í°ì„ ìƒì„±í•  ë•Œ í˜¸ì¶œ (OpenAI/Claude ëª¨ë‘ ì§€ì›)"""
        if not token:
            return

        # Claude ëª¨ë¸ì˜ ê²½ìš° í† í°ì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìŒ
        if isinstance(token, list):
            for item in token:
                if isinstance(item, dict) and item.get('type') == 'text' and 'text' in item:
                    text_content = item['text']
                    if text_content:
                        self.streamed_tokens.append(text_content)
                        self.put_token(text_content)
            return

        # Claude ëª¨ë¸ì˜ ê²½ìš° í† í°ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìŒ
        if isinstance(token, dict):
            # text íƒ€ì…ì˜ ì²­í¬ë§Œ ì¶”ì¶œ
            if token.get('type') == 'text' and 'text' in token:
                text_content = token['text']
                if text_content:
                    self.streamed_tokens.append(text_content)
                    self.put_token(text_content)
            # tool_useë‚˜ ë‹¤ë¥¸ íƒ€ì…ì€ ë¬´ì‹œ
            return

        # OpenAI ë“± ë¬¸ìì—´ë¡œ ì˜¤ëŠ” ê²½ìš°
        if isinstance(token, str):
            self.streamed_tokens.append(token)
            self.put_token(token)

    async def on_agent_action(self, action, **kwargs) -> None:
        """Agentê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ë•Œ í˜¸ì¶œ"""
        # pass
        tool_name = action.tool
        tool_input = str(action.tool_input)
        log_entry = f"<TOOLUSELOG>{tool_name}\n{tool_input}</TOOLUSELOG>"
        self.tool_logs.append(log_entry)
        self.put_status(f"{log_entry}\n")

    async def on_tool_start(self, serialized, input_str, **kwargs) -> None:
        """ë„êµ¬ ì‹¤í–‰ ì‹œì‘ ì‹œ"""
        pass

    async def on_tool_end(self, output, **kwargs) -> None:
        """ë„êµ¬ ì‹¤í–‰ì´ ì™„ë£Œë  ë•Œ í˜¸ì¶œ"""

        self.tool_outputs.append(output)

        if isinstance(output, (dict, list)):
            try:
                import json

                tool_output = json.dumps(output, ensure_ascii=False, indent=2)
            except Exception:
                tool_output = str(output)
        else:
            tool_output = str(output)

        parsed_output = _parse_document_citations(tool_output)
        display_output = parsed_output.strip() if parsed_output.strip() else tool_output.strip()

        if len(display_output) > 1200:
            display_output = display_output[:1200].rstrip() + "..."

        log_entry = f"<TOOLOUTPUTLOG>{display_output}</TOOLOUTPUTLOG>"
        self.tool_logs.append(log_entry)

        self.put_status(f"{log_entry}\n")

    async def on_tool_error(self, error, **kwargs) -> None:
        self.put_status(f"âŒ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(error)}\n")

    async def on_agent_finish(self, finish, **kwargs) -> None:
        pass

    # LangGraph ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ ë©”ì„œë“œ
    async def on_chain_start(self, serialized, inputs, **kwargs) -> None:
        """Chain ì‹œì‘ ì‹œ í˜¸ì¶œ (LangGraph ë…¸ë“œ ì‹¤í–‰ ì‹œì‘)"""
        pass

    async def on_chain_end(self, outputs, **kwargs) -> None:
        """Chain ì¢…ë£Œ ì‹œ í˜¸ì¶œ (LangGraph ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ)"""
        pass

    async def on_chain_error(self, error, **kwargs) -> None:
        """Chain ì˜¤ë¥˜ ì‹œ í˜¸ì¶œ"""
        self.put_error(error)

def execute_agent_streaming(
    async_executor_func: Callable[[], Awaitable[Any]],
    handler: EnhancedAgentStreamingHandler
) -> Generator[str, None, None]:
    """
    Agent ì‹¤í–‰ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë²”ìš© í•¨ìˆ˜
    LangGraph 1.0.0+ CompiledStateGraph ì§€ì›

    Args:
        async_executor_func: ì‹¤í–‰í•  ë¹„ë™ê¸° í•¨ìˆ˜ (ì˜ˆ: lambda: agent_graph.ainvoke(inputs, {"callbacks": [handler]}))
        handler: ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬

    Yields:
        str: ìŠ¤íŠ¸ë¦¬ë°ëœ í† í°ë“¤
    """

    exception_container = [None]
    execution_finished = [False]

    def run_agent():
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            async def execute_agent():
                try:
                    # ì „ë‹¬ë°›ì€ ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
                    result = await async_executor_func()
                    await asyncio.sleep(0.05)
                    handler.finish()
                    execution_finished[0] = True
                    return result
                except Exception as e:
                    logger.error(f"Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)

                    # ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„±
                    error_detail = str(e)

                    # OpenAI API ì—ëŸ¬ ì²˜ë¦¬
                    if "404" in error_detail and "does not exist" in error_detail:
                        if "claude" in error_detail.lower():
                            error_message = "âŒ Claude ëª¨ë¸ì„ OpenAI APIë¡œ í˜¸ì¶œí•˜ë ¤ê³  í–ˆìŠµë‹ˆë‹¤. Anthropic API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
                        else:
                            error_message = f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {error_detail}"
                    elif "401" in error_detail or "authentication" in error_detail.lower():
                        error_message = "âŒ API ì¸ì¦ ì‹¤íŒ¨: API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    elif "429" in error_detail or "rate limit" in error_detail.lower():
                        error_message = "âŒ API ìš”ì²­ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
                    else:
                        error_message = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_detail}"

                    # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ handlerë¥¼ í†µí•´ ì „ë‹¬
                    handler.put_status(f"\n{error_message}\n")

                    # LangGraph ê´€ë ¨ ì˜¤ë¥˜ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ ì œê³µ
                    if "validation error" in str(e).lower():
                        if "function.arguments" in str(e):
                            logger.error("OpenAI Tool Calling validation error detected. This may be caused by:")
                            logger.error("1. Tool with empty or None args_schema")
                            logger.error("2. Tool function returning invalid argument format")
                            logger.error("3. Pydantic schema validation failure")
                        elif "messages" in str(e).lower():
                            logger.error("LangGraph state validation error. Check that:")
                            logger.error("1. Input format matches AgentState schema (must contain 'messages' key)")
                            logger.error("2. Messages are proper langchain_core.messages objects")

                    handler.put_error(e)
                    execution_finished[0] = True
                    raise e

            loop.run_until_complete(execute_agent())
        except Exception as e:
            exception_container[0] = e
            handler.put_error(e)
            execution_finished[0] = True
        finally:
            loop.close()

    thread = threading.Thread(target=run_agent, daemon=True)
    thread.start()

    try:
        while True:
            try:
                msg_type, value = handler.token_queue.get(timeout=2.0)
                if msg_type == 'token':
                    yield value
                elif msg_type == 'status':
                    yield value
                elif msg_type == 'done':
                    break
                elif msg_type == 'error':
                    if exception_container[0]:
                        raise exception_container[0]
                    elif value:
                        raise value
                    else:
                        raise RuntimeError("Unknown error occurred")

            except queue.Empty:
                # íê°€ ë¹„ì–´ìˆì„ ë•Œ ìŠ¤ë ˆë“œ ìƒíƒœ í™•ì¸
                if execution_finished[0] or not thread.is_alive():
                    # ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆì§€ë§Œ íì— 'done' ì‹ í˜¸ê°€ ì—†ëŠ” ê²½ìš°
                    if execution_finished[0] and handler.token_queue.empty():
                        break
                    # ìŠ¤ë ˆë“œê°€ ë¹„ì •ìƒ ì¢…ë£Œëœ ê²½ìš°
                    elif not thread.is_alive() and exception_container[0]:
                        raise exception_container[0]
                    elif not thread.is_alive():
                        break
                continue

    except Exception as e:
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©ìì—ê²Œ yield
        yield f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n"
    finally:
        # ìŠ¤ë ˆë“œ ì •ë¦¬
        if thread.is_alive():
            thread.join(timeout=10.0)
