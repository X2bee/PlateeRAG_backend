"""
ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , 
í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”ì— ì í•©í•œ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
import re
import base64
from pathlib import Path
from typing import List, Dict, Optional, Any
import aiofiles
import PyPDF2
from docx import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter, Language
from service.llm.llm_service import LLMService

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    from pdfminer.high_level import extract_text
    PDFMINER_AVAILABLE = True
except ImportError:
    PDFMINER_AVAILABLE = False

try:
    from pdf2image import convert_from_path
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage
    LANGCHAIN_OPENAI_AVAILABLE = True
except ImportError:
    LANGCHAIN_OPENAI_AVAILABLE = False

logger = logging.getLogger("document-processor")

LANGCHAIN_CODE_LANGUAGE_MAP = {
    'py': Language.PYTHON, 'js': Language.JS, 'ts': Language.TS,
    'java': Language.JAVA, 'cpp': Language.CPP, 'c': Language.CPP,
    'cs': Language.CSHARP, 'go': Language.GO, 'rs': Language.RUST,
    'php': Language.PHP, 'rb': Language.RUBY, 'swift': Language.SWIFT,
    'kt': Language.KOTLIN, 'scala': Language.SCALA,
    'html': Language.HTML, 'jsx': Language.JS, 'tsx': Language.TS,
}

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, collection_config=None):
        self.document_types = ['pdf', 'docx', 'doc']
        self.text_types = ['txt', 'md', 'markdown', 'rtf']
        self.code_types = ['py','js','ts','java','cpp','c','h','cs','go','rs',
                          'php','rb','swift','kt','scala','dart','r','sql',
                          'html','css','jsx','tsx','vue','svelte']
        self.config_types = ['json','yaml','yml','xml','toml','ini','cfg','conf','properties','env']
        self.data_types   = ['csv','tsv','xlsx','xls']
        self.script_types = ['sh','bat','ps1','zsh','fish']
        self.log_types    = ['log']
        self.web_types    = ['htm','xhtml']
        self.image_types  = ['jpg','jpeg','png','gif','bmp','webp']
        self.supported_types = (
            self.document_types + self.text_types + self.code_types +
            self.config_types + self.data_types + self.script_types +
            self.log_types + self.web_types + self.image_types
        )
        self.collection_config = collection_config
        
        if not PANDAS_AVAILABLE:
            self.supported_types = [t for t in self.supported_types if t not in ['xlsx','xls']]
        if not LANGCHAIN_OPENAI_AVAILABLE:
            self.supported_types = [t for t in self.supported_types if t not in self.image_types]
            logger.warning("langchain_openai not available. Image processing disabled.")
        self.encodings = ['utf-8','utf-8-sig','cp949','euc-kr','latin-1','ascii']
        if not PDFMINER_AVAILABLE:
            logger.warning("pdfminer not available. Using PyPDF2 fallback.")
        if not PDF2IMAGE_AVAILABLE:
            logger.warning("pdf2image not available. OCR disabled.")

    def _get_current_image_text_config(self) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ìœ¼ë¡œ í˜„ì¬ IMAGE_TEXT ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        try:
            from main import app
            if hasattr(app.state, 'config_composer'):
                collection_config = app.state.config_composer.get_config_by_category_name("collection")
                
                if hasattr(collection_config, 'get_env_value'):
                    config = {
                        'provider': collection_config.get_env_value('IMAGE_TEXT_MODEL_PROVIDER', 'no_model').lower(),
                        'base_url': collection_config.get_env_value('IMAGE_TEXT_BASE_URL', 'https://api.openai.com/v1'),
                        'api_key': collection_config.get_env_value('IMAGE_TEXT_API_KEY', ''),
                        'model': collection_config.get_env_value('IMAGE_TEXT_MODEL_NAME', 'gpt-4-vision-preview'),
                        'temperature': float(collection_config.get_env_value('IMAGE_TEXT_TEMPERATURE', '0.7'))
                    }
                    logger.debug(f"ğŸ”„ Real-time config loaded: provider={config['provider']}")
                    return config
        
        except Exception as e:
            logger.warning(f"Failed to get current config: {e}")
        
        # fallback to initialization config
        if isinstance(self.collection_config, dict):
            logger.debug("Using fallback initialization config")
            return self.collection_config
        else:
            logger.debug("Using default no_model config")
            return {'provider': 'no_model'}

    def _is_image_text_enabled(self, config: Dict[str, Any]) -> bool:
        """ì„¤ì •ì— ë”°ë¼ OCRì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        provider = config.get('provider', 'no_model')
        if provider in ('openai', 'vllm'):
            # OCR ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë”ì¸ì§€ í™•ì¸
            if not LANGCHAIN_OPENAI_AVAILABLE:
                logger.warning("langchain_openai not available for OCR")
                return False
            return True
        return False

    def get_supported_types(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ ëª©ë¡ ë°˜í™˜"""
        return self.supported_types.copy()
    
    def get_file_category(self, file_type: str) -> str:
        """íŒŒì¼ íƒ€ì…ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜"""
        file_type = file_type.lower()
        if file_type in self.document_types:
            return 'document'
        elif file_type in self.text_types:
            return 'text'
        elif file_type in self.code_types:
            return 'code'
        elif file_type in self.config_types:
            return 'config'
        elif file_type in self.data_types:
            return 'data'
        elif file_type in self.script_types:
            return 'script'
        elif file_type in self.log_types:
            return 'log'
        elif file_type in self.web_types:
            return 'web'
        elif file_type in self.image_types:
            return 'image'
        else:
            return 'unknown'
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
        text = re.sub(r'\s+', ' ', text)
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ ë‘ ê°œë¡œ ì œí•œ
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        return text.strip()
    
    def clean_code_text(self, text: str, file_type: str) -> str:
        """ì½”ë“œ í…ìŠ¤íŠ¸ ì •ë¦¬ (ì½”ë“œì˜ êµ¬ì¡°ë¥¼ ë³´ì¡´)"""
        if not text:
            return ""
        
        # ì½”ë“œ íŒŒì¼ì˜ ê²½ìš° ë“¤ì—¬ì“°ê¸°ì™€ ì¤„ë°”ê¿ˆì„ ë³´ì¡´
        # ë‹¤ë§Œ íŒŒì¼ ëì˜ ê³¼ë„í•œ ê³µë°±ì€ ì œê±°
        text = text.rstrip()
        
        # íƒ­ì„ 4ê°œì˜ ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€í™˜ (ì¼ê´€ì„±ì„ ìœ„í•´)
        text = text.replace('\t', '    ')
        
        return text
    
    async def _convert_image_to_text(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹¤ì‹œê°„ ì„¤ì • ì‚¬ìš©)"""
        # ğŸ”¥ ì‹¤ì‹œê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        current_config = self._get_current_image_text_config()
        
        if not self._is_image_text_enabled(current_config):
            return "[ì´ë¯¸ì§€ íŒŒì¼: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]"
        
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            provider = current_config.get('provider', 'openai')
            api_key = current_config.get('api_key', '')
            base_url = current_config.get('base_url', 'https://api.openai.com/v1')
            model = current_config.get('model', 'gpt-4-vision-preview')
            temperature = current_config.get('temperature', 0.7)
            
            logger.info(f'ğŸ”„ Using real-time image-text provider: {provider}')
            logger.info(f'Model: {model}, Base URL: {base_url}')
            
            # í”„ë¡œë°”ì´ë”ë³„ LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            if provider == 'openai':
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key,
                    base_url=base_url,
                    temperature=temperature
                )
            elif provider == 'vllm':
                # vLLMì˜ ê²½ìš° OpenAI í˜¸í™˜ API ì‚¬ìš©
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key or 'dummy',  # vLLMì€ ë³´í†µ API í‚¤ê°€ í•„ìš”ì—†ìŒ
                    base_url=base_url,
                    temperature=temperature
                )
            else:
                logger.error(f"Unsupported image-text provider: {provider}")
                return f"[ì´ë¯¸ì§€ íŒŒì¼: ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë” - {provider}]"
            
            # OCR í”„ë¡¬í”„íŠ¸
            prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ì •í™•í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ê·œì¹™ì„ ì² ì €íˆ ì§€ì¼œì£¼ì„¸ìš”:

1. **í‘œ êµ¬ì¡° ë³´ì¡´**: í‘œê°€ ìˆë‹¤ë©´ ì •í™•í•œ í–‰ê³¼ ì—´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê³ , ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”
2. **ë ˆì´ì•„ì›ƒ ìœ ì§€**: ì›ë³¸ì˜ ë ˆì´ì•„ì›ƒ, ë“¤ì—¬ì“°ê¸°, ì¤„ë°”ê¿ˆì„ ìµœëŒ€í•œ ë³´ì¡´í•´ì£¼ì„¸ìš”
3. **ì •í™•í•œ í…ìŠ¤íŠ¸**: ëª¨ë“  ë¬¸ì, ìˆ«ì, ê¸°í˜¸ë¥¼ ì •í™•íˆ ì¸ì‹í•´ì£¼ì„¸ìš”
4. **êµ¬ì¡° ì •ë³´**: ì œëª©, ë¶€ì œëª©, ëª©ë¡, ë‹¨ë½ êµ¬ë¶„ì„ ëª…í™•íˆ í‘œí˜„í•´ì£¼ì„¸ìš”
5. **íŠ¹ìˆ˜ í˜•ì‹**: ë‚ ì§œ, ê¸ˆì•¡, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ ë“±ì˜ í˜•ì‹ì„ ì •í™•íˆ ìœ ì§€í•´ì£¼ì„¸ìš”

ë§Œì•½ í‘œê°€ ìˆë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:
| í•­ëª© | ë‚´ìš© |
|------|------|
| ë°ì´í„°1 | ê°’1 |
| ë°ì´í„°2 | ê°’2 |

í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”."""

            # ì´ë¯¸ì§€ ë©”ì‹œì§€ ìƒì„±
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            )
            
            # ì‘ë‹µ ìƒì„±
            response = await llm.ainvoke([message])
            logger.info(f"Successfully converted image to text using {provider}: {Path(image_path).name}")
            return response.content
            
        except Exception as e:
            logger.error(f"Error converting image to text {image_path}: {e}")
            return f"[ì´ë¯¸ì§€ íŒŒì¼: í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}]"
    
    async def _extract_text_from_pdf(self, file_path: str) -> str:
        """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì‹¤ì‹œê°„ ì„¤ì •ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë˜ëŠ” OCR)"""
        try:
            # ğŸ”¥ ì‹¤ì‹œê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            current_config = self._get_current_image_text_config()
            provider = current_config.get('provider', 'no_model')
            
            logger.info(f"ğŸ”„ Real-time PDF processing with provider: {provider}")
            
            # no_modelì¸ ê²½ìš°ì—ë§Œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if provider == 'no_model':
                logger.info("Using text extraction mode (no_model)")
                
                # 1ë‹¨ê³„: pdfminer ì‹œë„
                if PDFMINER_AVAILABLE:
                    logger.info(f"Using pdfminer for {file_path}")
                    try:
                        text = extract_text(file_path)
                        cleaned_text = self.clean_text(text)
                        if len(cleaned_text.strip()) > 100:
                            logger.info(f"Text extracted via pdfminer: {len(cleaned_text)} chars")
                            return cleaned_text
                    except Exception as e:
                        logger.warning(f"pdfminer failed: {e}")
                        
                # 2ë‹¨ê³„: PyPDF2 fallback
                logger.info(f"Using PyPDF2 fallback for {file_path}")
                text = await self._extract_text_from_pdf_fallback(file_path)
                logger.info(f"Text extracted via PyPDF2: {len(text)} chars")
                return text  # no_modelì—ì„œëŠ” OCRë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
            
            else:
                # openai, vllm ë“± ë‹¤ë¥¸ í”„ë¡œë°”ì´ë”ì¸ ê²½ìš° ë¬´ì¡°ê±´ OCR
                logger.info(f"Using OCR mode with provider: {provider}")
                return await self._extract_text_from_pdf_via_ocr(file_path)
                
        except Exception as e:
            logger.error(f"PDF processing failed: {e}")
            
            # ì—ëŸ¬ ë°œìƒì‹œì—ë„ ì‹¤ì‹œê°„ ì„¤ì •ì— ë”°ë¼ ì²˜ë¦¬
            current_config = self._get_current_image_text_config()
            provider = current_config.get('provider', 'no_model')
            
            if provider == 'no_model':
                # no_modelì¸ ê²½ìš° ê¸°ë³¸ fallbackë§Œ ì‹œë„
                try:
                    return await self._extract_text_from_pdf_fallback(file_path)
                except:
                    return "[PDF íŒŒì¼: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]"
            else:
                # ë‹¤ë¥¸ í”„ë¡œë°”ì´ë”ì¸ ê²½ìš° OCR ì‹œë„
                return await self._extract_text_from_pdf_via_ocr(file_path)

    async def _extract_text_from_pdf_fallback(self, file_path: str) -> str:
        """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyPDF2 fallback)"""
        text = ""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page_num, page in enumerate(pdf_reader.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== í˜ì´ì§€ {page_num + 1} ===\n"
                        text += page_text + "\n"
            return self.clean_text(text)
        except Exception as e:
            logger.error(f"Error extracting text from PDF {file_path}: {e}")
            raise
    
    async def _extract_text_from_pdf_via_ocr(self, file_path: str) -> str:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCR ë©”ì„œë“œ ì‚¬ìš© (ì‹¤ì‹œê°„ ì„¤ì •)"""
        try:
            # PDF2IMAGEê°€ í•„ìš”
            if not PDF2IMAGE_AVAILABLE:
                logger.error("pdf2image not available for OCR processing")
                return "[PDF íŒŒì¼: pdf2image ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤]"
            
            # ì‹¤ì‹œê°„ ì„¤ì •ìœ¼ë¡œ OCR í™œì„±í™” ì—¬ë¶€ í™•ì¸
            current_config = self._get_current_image_text_config()
            if not self._is_image_text_enabled(current_config):
                logger.warning("OCR is disabled, falling back to text extraction")
                return await self._extract_text_from_pdf_fallback(file_path)
            
            import tempfile
            import os
            
            logger.info(f"Converting PDF to images for OCR: {file_path}")
            
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = convert_from_path(file_path, dpi=300)
            
            all_text = ""
            temp_files = []
            
            try:
                for i, image in enumerate(images):
                    # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ìƒì„±
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                        image.save(temp_file.name, 'PNG')
                        temp_files.append(temp_file.name)
                        
                        logger.info(f"Processing page {i+1}/{len(images)} via OCR")
                        
                        # OCR ë©”ì„œë“œ ì‚¬ìš© (ì‹¤ì‹œê°„ ì„¤ì • ì ìš©ë¨)
                        page_text = await self._convert_image_to_text(temp_file.name)
                        
                        if not page_text.startswith("[ì´ë¯¸ì§€ íŒŒì¼:"):  # ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°
                            all_text += f"\n=== í˜ì´ì§€ {i+1} (OCR) ===\n"
                            all_text += page_text + "\n"
                        else:
                            logger.warning(f"OCR failed for page {i+1}: {page_text}")
                            
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                for temp_file in temp_files:
                    try:
                        os.unlink(temp_file)
                    except:
                        pass
            
            if all_text.strip():
                logger.info(f"Successfully extracted text via OCR: {len(all_text)} chars")
                return self.clean_text(all_text)
            else:
                logger.warning("OCR failed, falling back to text extraction")
                return await self._extract_text_from_pdf_fallback(file_path)
                
        except Exception as e:
            logger.error(f"OCR processing failed for {file_path}: {e}")
            logger.warning("OCR failed, falling back to text extraction")
            return await self._extract_text_from_pdf_fallback(file_path)

    async def _extract_text_from_docx(self, file_path: str) -> str:
        """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í‘œ, ì´ë¯¸ì§€ í¬í•¨)"""
        try:
            doc = Document(file_path)
            text = ""
            processed_tables = set()  # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
            
            # ë°©ë²• 1: ë¬¸ì„œì˜ ëª¨ë“  ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ (ê³ ê¸‰ ë°©ë²•)
            try:
                for element in doc.element.body:
                    if element.tag.endswith('p'):  # ë‹¨ë½(paragraph)
                        para_text = self._extract_paragraph_text(element, doc)
                        if para_text.strip():
                            text += para_text + "\n"
                            
                    elif element.tag.endswith('tbl'):  # í‘œ(table)
                        table_text = self._extract_table_text(element)
                        if table_text.strip():
                            text += "\n=== í‘œ ===\n" + table_text + "\n=== í‘œ ë ===\n\n"
                            processed_tables.add(table_text)
                
                logger.info("Successfully used advanced DOCX parsing method")
            except Exception as e:
                logger.warning(f"Advanced parsing failed, falling back to simple method: {e}")
                # Fallback: ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ëª¨ë“  ë‹¨ë½ ì¶”ì¶œ
                text = ""
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():
                        text += paragraph.text + "\n"
            
            # ë°©ë²• 2: ëª¨ë“  í‘œë¥¼ í™•ì‹¤íˆ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
            for i, table in enumerate(doc.tables):
                table_text = self._extract_simple_table_text(table)
                if table_text.strip():
                    # ì´ë¯¸ ì²˜ë¦¬ëœ í‘œì¸ì§€ í™•ì¸ (ê°„ë‹¨í•œ ë¹„êµ)
                    is_duplicate = any(
                        self._is_similar_table_text(table_text, processed) 
                        for processed in processed_tables
                    )
                    
                    if not is_duplicate:
                        text += f"\n=== í‘œ {i+1} ===\n" + table_text + "\n=== í‘œ ë ===\n\n"
                        processed_tables.add(table_text)
            
            logger.info(f"Extracted {len(processed_tables)} tables from DOCX")
            return self.clean_text(text)
        except Exception as e:
            logger.error(f"Error extracting text from DOCX {file_path}: {e}")
            raise
    
    def _extract_paragraph_text(self, para_element, doc) -> str:
        """ë‹¨ë½ì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ"""
        try:
            text = ""
            nsmap = doc.element.nsmap if hasattr(doc.element, 'nsmap') else {}
            
            for run in para_element.findall('.//w:r', nsmap):
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                for text_elem in run.findall('.//w:t', nsmap):
                    if text_elem.text:
                        text += text_elem.text
                
                # ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
                for drawing in run.findall('.//w:drawing', nsmap):
                    # ì´ë¯¸ì§€ê°€ ìˆë‹¤ëŠ” í‘œì‹œ ì¶”ê°€
                    text += " [ì´ë¯¸ì§€] "
                    
                    # ì´ë¯¸ì§€ ì„¤ëª… í…ìŠ¤íŠ¸ ì°¾ê¸° (ê°€ëŠ¥í•œ ê²½ìš°)
                    try:
                        for desc in drawing.findall('.//wp:docPr', nsmap):
                            if desc.get('descr'):
                                text += f"[ì„¤ëª…: {desc.get('descr')}] "
                            elif desc.get('name'):
                                text += f"[ì´ë¦„: {desc.get('name')}] "
                    except:
                        pass  # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨í•´ë„ ê³„ì†
            
            return text
        except Exception as e:
            logger.debug(f"Error extracting paragraph text: {e}")
            # Fallback 1: ë” ê°„ë‹¨í•œ ë°©ë²•
            try:
                text_elements = para_element.findall('.//w:t', {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})
                return ''.join([elem.text or '' for elem in text_elements])
            except:
                # Fallback 2: ìµœì¢… ë°©ë²•
                try:
                    return para_element.text or ""
                except:
                    return ""
   
    def _extract_table_text(self, table_element) -> str:
        """í‘œ ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text = ""
            # namespace ì •ì˜
            ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
            
            # XMLì—ì„œ ì§ì ‘ í‘œ ë°ì´í„° ì¶”ì¶œ
            for row in table_element.findall('.//w:tr', ns):
                row_text = []
                for cell in row.findall('.//w:tc', ns):
                    cell_text = ""
                    for text_elem in cell.findall('.//w:t', ns):
                        if text_elem.text:
                            cell_text += text_elem.text
                    row_text.append(cell_text.strip())
                
                if any(cell.strip() for cell in row_text):  # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    text += " | ".join(row_text) + "\n"
            
            return text
        except Exception as e:
            logger.debug(f"Error extracting table text: {e}")
            return ""
    
    def _extract_simple_table_text(self, table) -> str:
        """python-docx Table ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text = ""
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    cell_text = cell.text.strip()
                    row_text.append(cell_text)
                
                if any(cell.strip() for cell in row_text):  # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    text += " | ".join(row_text) + "\n"
            
            return text
        except Exception as e:
            logger.debug(f"Error extracting simple table text: {e}")
            return ""
    
    async def extract_text_from_file(self, file_path: str, file_extension: str) -> str:
        """íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì ì ˆí•œ ë©”ì„œë“œ í˜¸ì¶œ)
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            file_extension: íŒŒì¼ í™•ì¥ì
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            
        Raises:
            Exception: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨
        """
        try:
            category = self.get_file_category(file_extension)
            
            logger.info(f"Extracting text from {file_extension} file ({category} category): {file_path}")
            
            # íŒŒì¼ í˜•ì‹ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if file_extension == 'pdf':
                return await self._extract_text_from_pdf(file_path)
            elif file_extension in ['docx', 'doc']:
                return await self._extract_text_from_docx(file_path)
            elif file_extension in ['xlsx', 'xls']:
                return await self._extract_text_from_excel(file_path)
            elif file_extension in self.image_types:
                return await self._convert_image_to_text(file_path)
            elif file_extension in (self.text_types + self.code_types + self.config_types + 
                                self.script_types + self.log_types + self.web_types):
                return await self._extract_text_from_text_file(file_path, file_extension)
            else:
                raise ValueError(f"Unsupported file type: {file_extension}")
            
        except Exception as e:
            logger.error(f"Failed to extract text from {file_path}: {e}")
            raise

    def _is_similar_table_text(self, text1: str, text2: str, threshold: float = 0.8) -> bool:
        """ë‘ í‘œ í…ìŠ¤íŠ¸ê°€ ìœ ì‚¬í•œì§€ í™•ì¸ (ì¤‘ë³µ ì œê±°ìš©)"""
        try:
            if not text1 or not text2:
                return False
            
            # ê³µë°± ì •ê·œí™”
            text1_clean = re.sub(r'\s+', ' ', text1.strip())
            text2_clean = re.sub(r'\s+', ' ', text2.strip())
            
            # ì™„ì „íˆ ë™ì¼í•œ ê²½ìš°
            if text1_clean == text2_clean:
                return True
            
            # ê¸¸ì´ê°€ ë§¤ìš° ë‹¤ë¥¸ ê²½ìš°
            len1, len2 = len(text1_clean), len(text2_clean)
            if min(len1, len2) / max(len1, len2) < 0.5:
                return False
            
            # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê²€ì‚¬ (ê³µí†µ ë¶€ë¶„ ë¹„ìœ¨)
            shorter = text1_clean if len1 < len2 else text2_clean
            longer = text2_clean if len1 < len2 else text1_clean
            
            common_ratio = len(set(shorter.split()) & set(longer.split())) / len(set(shorter.split()))
            return common_ratio >= threshold
            
        except Exception:
            return False
    
    async def _extract_text_from_excel(self, file_path: str) -> str:
        """Excel íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not PANDAS_AVAILABLE:
            raise Exception("pandas is required for Excel file processing but is not available")
        
        try:
            # Excel íŒŒì¼ ì½ê¸° (ëª¨ë“  ì‹œíŠ¸)
            excel_file = pd.ExcelFile(file_path)
            text = ""
            
            for sheet_name in excel_file.sheet_names:
                logger.info(f"Processing sheet: {sheet_name}")
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                
                # ì‹œíŠ¸ ì´ë¦„ ì¶”ê°€
                text += f"\n=== ì‹œíŠ¸: {sheet_name} ===\n"
                
                # ì»¬ëŸ¼ í—¤ë” ì¶”ê°€
                if not df.empty:
                    text += "ì»¬ëŸ¼: " + ", ".join(str(col) for col in df.columns) + "\n\n"
                    
                    # ë°ì´í„° í–‰ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    for index, row in df.iterrows():
                        row_text = " | ".join(str(value) for value in row.values if pd.notna(value))
                        if row_text.strip():  # ë¹ˆ í–‰ ì œì™¸
                            text += row_text + "\n"
                    text += "\n"
            
            return self.clean_text(text)
        except Exception as e:
            logger.error(f"Error extracting text from Excel {file_path}: {e}")
            raise
    
    async def _extract_text_from_text_file(self, file_path: str, file_type: str) -> str:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„)"""
        category = self.get_file_category(file_type)
        
        for encoding in self.encodings:
            try:
                async with aiofiles.open(file_path, 'r', encoding=encoding) as file:
                    text = await file.read()
                
                logger.info(f"Successfully read {file_path} with {encoding} encoding")
                
                # íŒŒì¼ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë‹¤ë¥¸ ì •ë¦¬ ë°©ì‹ ì ìš©
                if category == 'code':
                    return self.clean_code_text(text, file_type)
                else:
                    return self.clean_text(text)
                    
            except UnicodeDecodeError:
                logger.debug(f"Failed to read {file_path} with {encoding} encoding, trying next...")
                continue
            except Exception as e:
                logger.error(f"Error reading file {file_path} with {encoding} encoding: {e}")
                continue
        
        # ëª¨ë“  ì¸ì½”ë”©ì´ ì‹¤íŒ¨í•œ ê²½ìš°
        raise Exception(f"Could not read file {file_path} with any supported encoding")
    
    def chunk_text(self, text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            text: ë¶„í• í•  í…ìŠ¤íŠ¸
            chunk_size: ì²­í¬ í¬ê¸°
            chunk_overlap: ì²­í¬ ê°„ ì¤‘ë³µ í¬ê¸°
            
        Returns:
            ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
            
        Raises:
            Exception: í…ìŠ¤íŠ¸ ë¶„í•  ì˜¤ë¥˜
        """
        try:
            if not text or not text.strip():
                logger.warning("Empty text provided for chunking")
                return [""]
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                length_function=len,
                separators=["\n\n", "\n", " ", ""]
            )
            chunks = text_splitter.split_text(text)
            logger.info(f"Text split into {len(chunks)} chunks (size: {chunk_size}, overlap: {chunk_overlap})")
            return chunks
        except Exception as e:
            logger.error(f"Error chunking text: {e}")
            raise
    
    def chunk_code_text(self, text: str, file_type: str, chunk_size: int = 1500, chunk_overlap: int = 300) -> List[str]:
        """ì½”ë“œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ì–¸ì–´ë³„ êµ¬ë¬¸ êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ë¶„í• )
            
        Args:
            text: ë¶„í• í•  ì½”ë“œ í…ìŠ¤íŠ¸
            file_type: íŒŒì¼ í˜•ì‹
            chunk_size: ì²­í¬ í¬ê¸° (ì½”ë“œëŠ” ì¢€ ë” í° ì²­í¬ ì‚¬ìš©)
            chunk_overlap: ì²­í¬ ê°„ ì¤‘ë³µ í¬ê¸°
            
        Returns:
            ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not text or not text.strip():
                logger.warning("Empty code text provided for chunking")
                return [""]
            
            lang = LANGCHAIN_CODE_LANGUAGE_MAP.get(file_type.lower())

            if lang:
                text_splitter = RecursiveCharacterTextSplitter.from_language(
                    language=lang,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                )
                logger.info(f"Using language-specific splitter for {file_type} ({lang})")
            else:
                # fallback: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                logger.info(f"No language-specific splitter for {file_type}, using fallback.")
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    length_function=len,
                    separators=["\n\n", "\n", " ", ""]
                )

            chunks = text_splitter.split_text(text)
            logger.info(f"Code text split into {len(chunks)} chunks (size: {chunk_size}, overlap: {chunk_overlap})")
            return chunks
        except Exception as e:
            logger.error(f"Error chunking code text: {e}")
            raise
    
    def validate_file_format(self, file_path: str) -> tuple[bool, str]:
        """íŒŒì¼ í˜•ì‹ ìœ íš¨ì„± ê²€ì‚¬
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            (ìœ íš¨ì„±, íŒŒì¼í˜•ì‹) íŠœí”Œ
        """
        try:
            file_extension = Path(file_path).suffix[1:].lower()
            is_valid = file_extension in self.supported_types
            return is_valid, file_extension
        except Exception:
            return False, ""
    
    def estimate_chunks_count(self, text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> int:
        """í…ìŠ¤íŠ¸ì—ì„œ ìƒì„±ë  ì²­í¬ ìˆ˜ ì¶”ì •
        
        Args:
            text: ëŒ€ìƒ í…ìŠ¤íŠ¸
            chunk_size: ì²­í¬ í¬ê¸°
            chunk_overlap: ì²­í¬ ê°„ ì¤‘ë³µ í¬ê¸°
            
        Returns:
            ì˜ˆìƒ ì²­í¬ ìˆ˜
        """
        if not text:
            return 0
        
        text_length = len(text)
        if text_length <= chunk_size:
            return 1
        
        # ê°„ë‹¨í•œ ì¶”ì • ê³µì‹
        effective_chunk_size = chunk_size - chunk_overlap
        estimated_chunks = (text_length - chunk_overlap) // effective_chunk_size + 1
        return max(1, estimated_chunks)
    
    def get_file_info(self, file_path: str) -> Dict[str, str]:
        """íŒŒì¼ ì •ë³´ ë°˜í™˜
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            íŒŒì¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (extension, category, supported)
        """
        try:
            file_extension = Path(file_path).suffix[1:].lower()
            category = self.get_file_category(file_extension)
            is_supported = file_extension in self.supported_types
            
            return {
                'extension': file_extension,
                'category': category,
                'supported': str(is_supported)
            }
        except Exception:
            return {
                'extension': 'unknown',
                'category': 'unknown', 
                'supported': 'false'
            }

    def get_current_config_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ì„¤ì • ìƒíƒœ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
        try:
            current_config = self._get_current_image_text_config()
            return {
                "provider": current_config.get('provider', 'unknown'),
                "ocr_enabled": self._is_image_text_enabled(current_config),
                "base_url": current_config.get('base_url', 'unknown'),
                "model": current_config.get('model', 'unknown'),
                "temperature": current_config.get('temperature', 'unknown'),
                "langchain_available": LANGCHAIN_OPENAI_AVAILABLE,
                "pdf2image_available": PDF2IMAGE_AVAILABLE
            }
        except Exception as e:
            return {"error": str(e)}

    def test(self):
        """ì„¤ì • í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ (ë””ë²„ê¹…ìš©)"""
        try:
            current_config = self._get_current_image_text_config()
            provider = current_config.get('provider', 'no_model')
            
            logger.info(f"ğŸ” Test - Current provider: {provider}")
            logger.info(f"ğŸ” Test - Current config: {current_config}")
            logger.info(f"ğŸ” Test - OCR enabled: {self._is_image_text_enabled(current_config)}")
            
        except Exception as e:
            logger.error(f"Error in test method: {e}")
            raise