"""
OCR ì²˜ë¦¬ ëª¨ë“ˆ
"""

import base64
import logging
import tempfile
import os
import re
from pathlib import Path
from typing import List, Dict, Any

from .dependencies import (
    LANGCHAIN_OPENAI_AVAILABLE, PDF2IMAGE_AVAILABLE, 
    DOCX2PDF_AVAILABLE, PIL_AVAILABLE, PYTHON_PPTX_AVAILABLE
)
from .constants import OCR_SINGLE_PROMPT, get_batch_ocr_prompt

# ê¸°ë³¸ê°’ ì„¤ì •: ì¡°ê±´ë¶€ import ì‹œ ì‚¬ìš©ë˜ì§€ ì•Šì„ ê²½ìš°ì— ëŒ€ë¹„
ChatOpenAI = None
HumanMessage = None
convert_from_path = None
Presentation = None
Image = None
ImageDraw = None
ImageFont = None

if LANGCHAIN_OPENAI_AVAILABLE:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage

if PDF2IMAGE_AVAILABLE:
    from pdf2image import convert_from_path

docx_to_pdf_convert = None

if DOCX2PDF_AVAILABLE:
    from docx2pdf import convert as docx_to_pdf_convert

if PYTHON_PPTX_AVAILABLE:
    from pptx import Presentation

if PIL_AVAILABLE:
    from PIL import Image, ImageDraw, ImageFont

logger = logging.getLogger("document-processor")

class OCRProcessor:
    """OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
    
    async def convert_images_to_text_batch(self, image_paths: List[str], batch_size: int = 1) -> List[str]:
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜"""
        current_config = self.config_manager.get_current_image_text_config()
        
        if not self.config_manager.is_image_text_enabled(current_config):
            return ["[ì´ë¯¸ì§€ íŒŒì¼: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]" for _ in image_paths]
        
        # ë°°ì¹˜ í¬ê¸° ì œí•œ (1-10)
        batch_size = max(1, min(batch_size, 10))
        
        results = []
        total_batches = (len(image_paths) + batch_size - 1) // batch_size
        
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i+batch_size]
            batch_num = (i // batch_size) + 1
            
            logger.info(f"Processing batch {batch_num}/{total_batches} with {len(batch_paths)} images")
            
            if len(batch_paths) == 1:
                # ë‹¨ì¼ ì´ë¯¸ì§€ëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                result = await self.convert_image_to_text(batch_paths[0])
                results.append(result)
            else:
                # ì—¬ëŸ¬ ì´ë¯¸ì§€ëŠ” ë°°ì¹˜ ì²˜ë¦¬
                batch_results = await self._convert_multiple_images_to_text(batch_paths, current_config)
                results.extend(batch_results)
        
        return results

    async def _convert_multiple_images_to_text(self, image_paths: List[str], config: Dict[str, Any]) -> List[str]:
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œë²ˆì— OCR ì²˜ë¦¬"""
        try:
            # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            image_contents = []
            for image_path in image_paths:
                with open(image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                    image_contents.append(base64_image)
            
            provider = config.get('provider', 'openai')
            api_key = config.get('api_key', '')
            base_url = config.get('base_url', 'https://api.openai.com/v1')
            model = config.get('model', 'gpt-4-vision-preview')
            temperature = config.get('temperature', 0.7)
            
            logger.info(f'ğŸ”„ Using batch OCR with {len(image_paths)} images, provider: {provider}')
            
            # í”„ë¡œë°”ì´ë”ë³„ LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            if provider == 'openai':
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key,
                    base_url=base_url,
                    temperature=temperature
                )
            elif provider == 'vllm':
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key or 'dummy',
                    base_url=base_url,
                    temperature=temperature
                )
            else:
                logger.error(f"Unsupported image-text provider: {provider}")
                return [f"[ì´ë¯¸ì§€ íŒŒì¼: ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë” - {provider}]" for _ in image_paths]
            
            # ë°°ì¹˜ OCR í”„ë¡¬í”„íŠ¸
            prompt = get_batch_ocr_prompt(len(image_paths))
            
            # ë©€í‹° ì´ë¯¸ì§€ ë©”ì‹œì§€ ìƒì„±
            content = [{"type": "text", "text": prompt}]
            
            for i, base64_image in enumerate(image_contents):
                content.append({
                    "type": "image_url", 
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                })
            
            message = HumanMessage(content=content)
            
            # ì‘ë‹µ ìƒì„±
            response = await llm.ainvoke([message])
            response_text = response.content
            
            # ì‘ë‹µì„ ì´ë¯¸ì§€ë³„ë¡œ ë¶„í• 
            results = self._parse_batch_ocr_response(response_text, len(image_paths))
            
            logger.info(f"Successfully processed {len(image_paths)} images in batch")
            return results
            
        except Exception as e:
            logger.error(f"Error in batch OCR processing: {e}")
            # ì‹¤íŒ¨ì‹œ ê°œë³„ ì²˜ë¦¬ë¡œ fallback
            logger.warning("Batch OCR failed, falling back to individual processing")
            results = []
            for image_path in image_paths:
                result = await self.convert_image_to_text(image_path)
                results.append(result)
            return results

    def _parse_batch_ocr_response(self, response_text: str, expected_count: int) -> List[str]:
        """ë°°ì¹˜ OCR ì‘ë‹µì„ ì´ë¯¸ì§€ë³„ë¡œ ë¶„í• """
        try:
            # "=== ì´ë¯¸ì§€ N ===" íŒ¨í„´ìœ¼ë¡œ ë¶„í• 
            pattern = r'=== ì´ë¯¸ì§€ (\d+) ===\s*(.*?)(?=\s*=== ì´ë¯¸ì§€ \d+ ===|\s*$)'
            matches = re.findall(pattern, response_text, re.DOTALL)
            
            results = []
            
            if matches and len(matches) >= expected_count:
                # ë§¤ì¹­ëœ ê²°ê³¼ ì‚¬ìš©
                for i in range(expected_count):
                    if i < len(matches):
                        _, content = matches[i]
                        results.append(content.strip())
                    else:
                        results.append("[ì´ë¯¸ì§€ ë¶„í•  ì‹¤íŒ¨]")
            else:
                # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ ë¶„í• 
                logger.warning("Pattern matching failed, using simple split")
                parts = re.split(r'=== ì´ë¯¸ì§€ \d+ ===', response_text)
                
                for i in range(expected_count):
                    if i + 1 < len(parts):
                        results.append(parts[i + 1].strip())
                    else:
                        results.append("[ì´ë¯¸ì§€ ë¶„í•  ì‹¤íŒ¨]")
            
            # ê²°ê³¼ ê°œìˆ˜ ë§ì¶”ê¸°
            while len(results) < expected_count:
                results.append("[ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨]")
            
            return results[:expected_count]
            
        except Exception as e:
            logger.error(f"Error parsing batch OCR response: {e}")
            # ì‹¤íŒ¨ì‹œ ë™ì¼í•œ ì‘ë‹µì„ ëª¨ë“  ì´ë¯¸ì§€ì— ì ìš©
            return [response_text for _ in range(expected_count)]
    
    async def convert_image_to_text(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        current_config = self.config_manager.get_current_image_text_config()
        
        if not self.config_manager.is_image_text_enabled(current_config):
            return "[ì´ë¯¸ì§€ íŒŒì¼: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]"
        
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            provider = current_config.get('provider', 'openai')
            api_key = current_config.get('api_key', '')
            base_url = current_config.get('base_url', 'https://api.openai.com/v1')
            model = current_config.get('model', 'gpt-4-vision-preview')
            temperature = current_config.get('temperature', 0.7)
            
            logger.info(f'ğŸ”„ Using real-time image-text provider: {provider}')
            logger.info(f'Model: {model}, Base URL: {base_url}')
            
            # í”„ë¡œë°”ì´ë”ë³„ LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            if provider == 'openai':
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key,
                    base_url=base_url,
                    temperature=temperature
                )
            elif provider == 'vllm':
                llm = ChatOpenAI(
                    model=model,
                    openai_api_key=api_key or 'dummy',
                    base_url=base_url,
                    temperature=temperature
                )
            else:
                logger.error(f"Unsupported image-text provider: {provider}")
                return f"[ì´ë¯¸ì§€ íŒŒì¼: ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë” - {provider}]"
            
            # ì´ë¯¸ì§€ ë©”ì‹œì§€ ìƒì„±
            message = HumanMessage(
                content=[
                    {"type": "text", "text": OCR_SINGLE_PROMPT},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            )
            
            # ì‘ë‹µ ìƒì„±
            response = await llm.ainvoke([message])
            logger.info(f"Successfully converted image to text using {provider}: {Path(image_path).name}")
            return response.content
            
        except Exception as e:
            logger.error(f"Error converting image to text {image_path}: {e}")
            return f"[ì´ë¯¸ì§€ íŒŒì¼: í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}]"

    # ì´ë¯¸ì§€ ë³€í™˜ ë©”ì„œë“œë“¤
    async def convert_pdf_to_images(self, file_path: str) -> List[str]:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì„ì‹œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        if not PDF2IMAGE_AVAILABLE:
            logger.error("pdf2image not available for OCR processing")
            return []
        
        try:
            logger.info(f"Converting PDF to images for OCR: {file_path}")
            
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = convert_from_path(file_path, dpi=300)
            
            temp_files = []
            
            # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            for i, image in enumerate(images):
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                    image.save(temp_file.name, 'PNG')
                    temp_files.append(temp_file.name)
            
            return temp_files
            
        except Exception as e:
            logger.error(f"Error converting PDF to images: {e}")
            return []

    async def convert_docx_to_images(self, file_path: str) -> List[str]:
        """DOCXë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì„ì‹œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        temp_files = []
        
        try:
            # ë°©ë²• 1: docx2pdf + pdf2image ì‚¬ìš© (ê°€ì¥ ê¶Œì¥)
            if DOCX2PDF_AVAILABLE and PDF2IMAGE_AVAILABLE:
                logger.info("Converting DOCX to PDF, then to images using docx2pdf + pdf2image")
                
                with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
                    # DOCXë¥¼ PDFë¡œ ë³€í™˜
                    docx_to_pdf_convert(file_path, temp_pdf.name)
                    
                    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    images = convert_from_path(temp_pdf.name, dpi=300)
                    
                    for i, image in enumerate(images):
                        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_img:
                            image.save(temp_img.name, 'PNG')
                            temp_files.append(temp_img.name)
                    
                    # ì„ì‹œ PDF íŒŒì¼ ì‚­ì œ
                    os.unlink(temp_pdf.name)
                    
                return temp_files
            
            # ë°©ë²• 2: LibreOffice ì»¤ë§¨ë“œë¼ì¸ ì‚¬ìš©
            elif PDF2IMAGE_AVAILABLE:
                logger.info("Trying LibreOffice command-line conversion")
                import subprocess
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    try:
                        # LibreOfficeë¡œ DOCXë¥¼ PDFë¡œ ë³€í™˜
                        subprocess.run([
                            'libreoffice', '--headless', '--convert-to', 'pdf',
                            '--outdir', temp_dir, file_path
                        ], check=True, capture_output=True)
                        
                        # ë³€í™˜ëœ PDF íŒŒì¼ ì°¾ê¸°
                        pdf_name = Path(file_path).stem + '.pdf'
                        pdf_path = os.path.join(temp_dir, pdf_name)
                        
                        if os.path.exists(pdf_path):
                            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                            images = convert_from_path(pdf_path, dpi=300)
                            
                            for i, image in enumerate(images):
                                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_img:
                                    image.save(temp_img.name, 'PNG')
                                    temp_files.append(temp_img.name)
                            
                            return temp_files
                        
                    except (subprocess.CalledProcessError, FileNotFoundError) as e:
                        logger.warning(f"LibreOffice conversion failed: {e}")
            
            # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°
            logger.error("No available method to convert DOCX to images")
            return []
            
        except Exception as e:
            logger.error(f"Error converting DOCX to images: {e}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
            return []

    async def convert_ppt_to_images(self, file_path: str) -> List[str]:
        """PPTë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì„ì‹œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        temp_files = []
        
        try:
            # ë°©ë²• 1: LibreOffice ì»¤ë§¨ë“œë¼ì¸ ì‚¬ìš© (ê°€ì¥ ê¶Œì¥)
            if PDF2IMAGE_AVAILABLE:
                logger.info("Converting PPT to PDF, then to images using LibreOffice + pdf2image")
                import subprocess
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    try:
                        # LibreOfficeë¡œ PPTë¥¼ PDFë¡œ ë³€í™˜
                        subprocess.run([
                            'libreoffice', '--headless', '--convert-to', 'pdf',
                            '--outdir', temp_dir, file_path
                        ], check=True, capture_output=True)
                        
                        # ë³€í™˜ëœ PDF íŒŒì¼ ì°¾ê¸°
                        pdf_name = Path(file_path).stem + '.pdf'
                        pdf_path = os.path.join(temp_dir, pdf_name)
                        
                        if os.path.exists(pdf_path):
                            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                            images = convert_from_path(pdf_path, dpi=300)
                            
                            for i, image in enumerate(images):
                                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_img:
                                    image.save(temp_img.name, 'PNG')
                                    temp_files.append(temp_img.name)
                            
                            return temp_files
                        
                    except (subprocess.CalledProcessError, FileNotFoundError) as e:
                        logger.warning(f"LibreOffice PPT conversion failed: {e}")
            
            # ë°©ë²• 2: python-pptx + PILì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ë Œë”ë§ (fallback, í’ˆì§ˆ ë‚®ìŒ)
            if PIL_AVAILABLE and PYTHON_PPTX_AVAILABLE:
                logger.warning("Using fallback PIL text rendering for PPT (low quality)")
                return await self._render_ppt_text_to_images(file_path)
            
            # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°
            logger.error("No available method to convert PPT to images")
            return []
            
        except Exception as e:
            logger.error(f"Error converting PPT to images: {e}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
            return []

    async def _render_ppt_text_to_images(self, file_path: str) -> List[str]:
        """PPT í…ìŠ¤íŠ¸ë¥¼ PILë¡œ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (fallback ë°©ë²•)"""
        try:
            # PPTì—ì„œ ìŠ¬ë¼ì´ë“œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            prs = Presentation(file_path)
            temp_files = []
            
            for slide_num, slide in enumerate(prs.slides):
                # ìŠ¬ë¼ì´ë“œì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
                slide_text = ""
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        slide_text += shape.text + "\n"
                
                if not slide_text.strip():  # ë¹ˆ ìŠ¬ë¼ì´ë“œ ìŠ¤í‚µ
                    continue
                
                # ì´ë¯¸ì§€ ìƒì„±
                img_width, img_height = 1200, 900  # ìŠ¬ë¼ì´ë“œ ë¹„ìœ¨ (4:3)
                img = Image.new('RGB', (img_width, img_height), color='white')
                draw = ImageDraw.Draw(img)
                
                try:
                    # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                    font = ImageFont.load_default()
                except:
                    font = None
                
                y_offset = 50
                line_height = 25
                
                # ìŠ¬ë¼ì´ë“œ ì œëª© ì¶”ê°€
                draw.text((50, y_offset), f"=== ìŠ¬ë¼ì´ë“œ {slide_num + 1} ===", 
                            fill='black', font=font)
                y_offset += line_height * 2
                
                # í…ìŠ¤íŠ¸ ë Œë”ë§
                lines = slide_text.split('\n')
                for line in lines:
                    if line.strip() and y_offset < img_height - 50:
                        # ê¸´ ì¤„ì€ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• 
                        if len(line) > 80:
                            words = line.split()
                            current_line = ""
                            for word in words:
                                if len(current_line + word) < 80:
                                    current_line += word + " "
                                else:
                                    if current_line.strip():
                                        draw.text((50, y_offset), current_line.strip(), 
                                                fill='black', font=font)
                                        y_offset += line_height
                                    current_line = word + " "
                            if current_line.strip():
                                draw.text((50, y_offset), current_line.strip(), 
                                        fill='black', font=font)
                                y_offset += line_height
                        else:
                            draw.text((50, y_offset), line, fill='black', font=font)
                            y_offset += line_height
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                    img.save(temp_file.name, 'PNG')
                    temp_files.append(temp_file.name)
            
            return temp_files
            
        except Exception as e:
            logger.error(f"Error rendering PPT text to images: {e}")
            return []