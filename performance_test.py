#!/usr/bin/env python3
"""
Performance Logger í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰: python performance_test.py
"""
import sys
import os
import json
import time
import asyncio
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.config_composer import config_composer
from database.connection import AppDatabaseManager
from models.performance import NodePerformance
from src.monitoring.performance_logger import PerformanceLogger
from controller.performanceController import PerformanceController

def get_existing_database():
    """ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¬ì‚¬ìš©"""
    print("ğŸ“ Using existing database connection...")
    
    try:
        # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        database_config = config_composer.initialize_database_config_only()
        if not database_config:
            print("âŒ Failed to get database configuration")
            return None
        
        # ê¸°ì¡´ ì—°ê²°ì„ ì¬ì‚¬ìš©í•˜ëŠ” ë§¤ë‹ˆì € ìƒì„±
        app_db = AppDatabaseManager(database_config)
        
        # NodePerformance ëª¨ë¸ë§Œ ì¶”ê°€ ë“±ë¡ (ì´ë¯¸ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ main.pyì—ì„œ ë“±ë¡ë¨)
        app_db.register_model(NodePerformance)
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if app_db.config_db_manager.connect():
            print("âœ… Database connection successful")
            
            # NodePerformance í…Œì´ë¸”ì´ ì—†ë‹¤ë©´ ìƒì„±
            try:
                create_query = NodePerformance.get_create_table_query(app_db.config_db_manager.db_type)
                app_db.config_db_manager.execute_query(create_query)
                print("âœ… NodePerformance table ready")
            except Exception as e:
                print(f"âš ï¸ Table creation info: {e}")
            
            return app_db
        else:
            print("âŒ Failed to connect to existing database")
            return None
            
    except Exception as e:
        print(f"âŒ Error accessing existing database: {e}")
        return None

def extract_workflow_info():
    """ì›Œí¬í”Œë¡œìš° ì •ë³´ ì¶”ì¶œ"""
    print("\nğŸ“‹ Extracting workflow information...")
    
    workflow_file = project_root / "downloads" / "Workflow.json"
    
    if not workflow_file.exists():
        print(f"âŒ Workflow file not found: {workflow_file}")
        return None, None
    
    try:
        # workflow_nameì€ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
        workflow_name = workflow_file.stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…
        
        # workflow_idëŠ” JSON íŒŒì¼ ë‚´ë¶€ì—ì„œ ì¶”ì¶œ
        with open(workflow_file, 'r', encoding='utf-8') as f:
            workflow_data = json.load(f)
            workflow_id = workflow_data.get('id', '')
        
        print(f"âœ… Workflow Name: {workflow_name}")
        print(f"âœ… Workflow ID: {workflow_id}")
        
        return workflow_name, workflow_id
        
    except Exception as e:
        print(f"âŒ Error extracting workflow info: {e}")
        return None, None

def simulate_node_execution(workflow_name, workflow_id, db_manager):
    """ë…¸ë“œ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜"""
    print("\nğŸ”„ Simulating node executions...")
    
    # í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œë“¤
    test_nodes = [
        {
            "node_id": "chat/openai-1752219026167",
            "node_name": "Chat OpenAI",
            "input_data": {"text": "Hello, how are you?"},
            "output_data": {"result": "I'm doing well, thank you!"},
            "simulation_time": 0.15  # 150ms
        },
        {
            "node_id": "math/add-123456789",
            "node_name": "Math Add",
            "input_data": {"a": 10, "b": 20},
            "output_data": {"result": 30},
            "simulation_time": 0.05  # 50ms
        },
        {
            "node_id": "tool/print-987654321",
            "node_name": "Print Tool",
            "input_data": {"value": "Test output"},
            "output_data": {"printed": True},
            "simulation_time": 0.02  # 20ms
        }
    ]
    
    execution_count = 0
    
    # ê° ë…¸ë“œë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    for round_num in range(1, 4):  # 3ë¼ìš´ë“œ
        print(f"\nğŸ“Š Round {round_num} execution...")
        
        for node in test_nodes:
            print(f"  ğŸš€ Executing {node['node_name']}...")
            
            # PerformanceLogger ì‚¬ìš©
            with PerformanceLogger(
                workflow_name=workflow_name,
                workflow_id=workflow_id,
                node_id=node["node_id"],
                node_name=node["node_name"],
                db_manager=db_manager
            ) as perf_logger:
                
                # ì‹¤ì œ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ (ì‹œê°„ì€ ë¼ìš´ë“œë§ˆë‹¤ ì•½ê°„ ë‹¤ë¥´ê²Œ)
                simulation_time = node["simulation_time"] * (0.8 + round_num * 0.1)
                time.sleep(simulation_time)
                
                # ì„±ëŠ¥ ë°ì´í„° ë¡œê¹…
                perf_logger.log(node["input_data"], node["output_data"])
                execution_count += 1
    
    print(f"\nâœ… Completed {execution_count} node executions")
    return execution_count

def test_performance_analysis(workflow_name, workflow_id, db_manager):
    """ì„±ëŠ¥ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“ˆ Testing performance analysis...")
    
    controller = PerformanceController(db_manager)
    
    # 1. ì „ì²´ ì„±ëŠ¥ ë°ì´í„° ì¡°íšŒ
    print("\n1ï¸âƒ£ Getting all performance data...")
    all_data = controller.get_performance_data(workflow_name, workflow_id)
    print(f"   Found {len(all_data)} performance records")
    
    if all_data:
        latest = all_data[0]
        print(f"   Latest execution: {latest.get('node_name')} - {latest.get('processing_time_ms')}ms")
    
    # 2. ì„±ëŠ¥ í‰ê·  ê³„ì‚°
    print("\n2ï¸âƒ£ Calculating performance average...")
    avg_data = controller.get_performance_average(workflow_name, workflow_id)
    
    if avg_data.get('execution_count', 0) > 0:
        avg_perf = avg_data['average_performance']
        print(f"   Execution Count: {avg_data['execution_count']}")
        print(f"   Average Processing Time: {avg_perf['processing_time_ms']}ms")
        print(f"   Average CPU Usage: {avg_perf['cpu_usage_percent']}%")
        print(f"   Average RAM Usage: {avg_perf['ram_usage_mb']}MB")
    else:
        print("   No performance data found for averaging")
    
    # 3. ë…¸ë“œë³„ ì„±ëŠ¥ ìš”ì•½
    print("\n3ï¸âƒ£ Getting node performance summary...")
    summary_data = controller.get_node_performance_summary(workflow_name, workflow_id)
    
    if summary_data.get('nodes_summary'):
        print(f"   Total Nodes: {summary_data['total_nodes']}")
        for node_summary in summary_data['nodes_summary']:
            print(f"   ğŸ“Œ {node_summary['node_name']}: {node_summary['avg_processing_time_ms']}ms (avg)")
    else:
        print("   No node summary data found")

def test_database_direct_query(db_manager):
    """ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ—„ï¸ Testing direct database query...")
    
    try:
        # ì§ì ‘ SQL ì¿¼ë¦¬ë¡œ ë°ì´í„° í™•ì¸
        query = "SELECT COUNT(*) as count FROM node_performance"
        result = db_manager.config_db_manager.execute_query(query)
        
        if result:
            count = result[0]['count']
            print(f"   Total records in node_performance table: {count}")
        else:
            print("   No results from database query")
            
    except Exception as e:
        print(f"   âŒ Database query error: {e}")

def cleanup_test_data(db_manager):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬"""
    print("\nğŸ§¹ Cleaning up test data...")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ
        query = "DELETE FROM node_performance WHERE workflow_name = 'Workflow'"
        db_manager.config_db_manager.execute_query(query)
        print("   âœ… Test data cleaned up")
        
    except Exception as e:
        print(f"   âŒ Cleanup error: {e}")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª Performance Logger Test")
    print("=" * 50)
    
    # 1. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‚¬ìš©
    db_manager = get_existing_database()
    if not db_manager:
        print("âŒ Database connection failed. Exiting.")
        return
    
    # 2. ì›Œí¬í”Œë¡œìš° ì •ë³´ ì¶”ì¶œ
    workflow_name, workflow_id = extract_workflow_info()
    if not workflow_name or not workflow_id:
        print("âŒ Workflow info extraction failed. Exiting.")
        return
    
    try:
        # 3. ë…¸ë“œ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
        execution_count = simulate_node_execution(workflow_name, workflow_id, db_manager)
        
        # 4. ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ í™•ì¸
        test_database_direct_query(db_manager)
        
        # 5. ì„±ëŠ¥ ë¶„ì„ í…ŒìŠ¤íŠ¸
        test_performance_analysis(workflow_name, workflow_id, db_manager)
        
        print("\nğŸ‰ All tests completed successfully!")
        
        # 6. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ (ì„ íƒì‚¬í•­)
        cleanup_choice = input("\nğŸ—‘ï¸ Clean up test data? (y/N): ").strip().lower()
        if cleanup_choice == 'y':
            cleanup_test_data(db_manager)
        
    except Exception as e:
        print(f"âŒ Test execution error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\nğŸ‘‹ Test completed.")

if __name__ == "__main__":
    main()
