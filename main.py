from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging
import os
import uuid
import json
import pyarrow.csv as pv
from pathlib import Path
from contextlib import asynccontextmanager
from controller.node.nodeApiController import register_node_api_routes

from controller.node.router import node_router
from controller.admin.router import admin_router
from controller.workflow.router import workflow_router
from controller.workflow.endpoints.auto_generation import router as auto_generation_router
from controller.rag.router import rag_router
from controller.audio.router import audio_router
from controller.data_manager.router import data_manager_router
from controller.model.router import model_router
from controller.tools.router import tool_router

from controller.trainController import router as trainRouter
from controller.llmController import router as llmRouter
from controller.performanceController import router as performanceRouter
from controller.interactionController import router as interactionRouter
from controller.huggingface.huggingfaceController import router as huggingfaceRouter
from controller.appController import router as appRouter
from controller.authController import router as authRouter
from controller.vast_proxy_controller import router as vastProxyRouter
from controller.promptController import router as promptRouter
from controller.mcpController import router as mcpRouter
from editor.node_composer import run_discovery, generate_json_spec, get_node_registry
from editor.async_workflow_executor import execution_manager
from config.config_composer import config_composer
from service.database.models import APPLICATION_MODELS
from service.database.models.prompts import Prompts
from service.database.models.workflow import WorkflowStoreMeta

from service.database import AppDatabaseManager
from service.embedding.embedding_factory import EmbeddingFactory
from service.stt.stt_factory import STTFactory
from service.tts.tts_factory import TTSFactory
from service.guarder.guarder_factory import GuarderFactory
from service.vast.proxy_client import VastProxyClient
from service.vector_db.vector_manager import VectorManager
from service.retrieval.document_processor.document_processor import DocumentProcessor
from service.retrieval.document_info_generator.document_info_generator import DocumentInfoGenerator
from service.data_manager.data_manager_register import DataManagerRegistry
from service.mlflow.mlflow_artifact_service import MLflowArtifactService
from service.sync.workflow_deploy_sync import sync_workflow_deploy_meta
from controller.helper.utils.workflow_helpers import workflow_data_synchronizer

def print_xgen_logo():
    logo = """
    â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
    â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘
     â•šâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘
     â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
    â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•

    ğŸš€ PlateeRAG Backend with XGEN Engine ğŸš€
    """
    print(logo)

def print_step_banner(step_num, title, description=""):
    """ê° ë‹¨ê³„ë³„ ë°°ë„ˆ ì¶œë ¥"""
    banner = f"""
    â”Œ{'â”€' * 60}â”
    â”‚  STEP {step_num}: {title:<50}â”‚
    {f'â”‚  {description:<58}â”‚' if description else ''}
    â””{'â”€' * 60}â”˜
    """
    print(banner)

def generate_prompt_uid(act_text: str) -> str:
    """act í…ìŠ¤íŠ¸ë¡œë¶€í„° prompt_uid ìƒì„±"""
    # ê³µë°±ì„ _ë¡œ ë³€ê²½í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜
    base_uid = act_text.replace(' ', '_').lower()
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì˜ë¬¸ì, ìˆ«ì, _ë§Œ ìœ ì§€)
    base_uid = ''.join(c for c in base_uid if c.isalnum() or c == '_')
    # UUID 8ìë¦¬ ì¶”ê°€
    unique_suffix = str(uuid.uuid4())[:8]
    return f"{base_uid}_{unique_suffix}"

def load_prompts_from_csv(app_db, csv_path: str):
    """
    CSV íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    í‘œì¤€ í˜•ì‹: ID, Prompt UID, Title, Content, Language, Public, Template, User ID, Username, Full Name, Metadata, Created At, Updated At
    """
    try:
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(csv_path).exists():
            logger.warning(f"âš ï¸  Prompts CSV file not found: {csv_path}")
            return {"success": False, "error": "CSV file not found"}

        # ì´ë¯¸ í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_templates = app_db.find_by_condition(Prompts, {"is_template": True}, limit=1)
        if existing_templates and len(existing_templates) > 0:
            logger.info(f"âš ï¸  Template prompts already exist in database ({len(existing_templates)} records). Skipping CSV import.")
            return {"success": True, "inserted_count": 0, "skipped": True, "message": "Templates already exist"}

        # PyArrowë¡œ CSV íŒŒì¼ ì½ê¸°
        table = pv.read_csv(csv_path)
        logger.info(f"ğŸ“„ Loaded CSV with {len(table)} rows")

        # ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        data = table.to_pydict()

        # í‘œì¤€ í˜•ì‹ ì»¬ëŸ¼ í™•ì¸ (ë‹¤ìš´ë¡œë“œ í˜•ì‹)
        required_columns = ['Prompt UID', 'Title', 'Content', 'Language', 'Public', 'Template']
        missing_columns = [col for col in required_columns if col not in data]
        if missing_columns:
            error_msg = f"Missing required columns: {missing_columns}. Expected standard format from download."
            logger.error(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}

        inserted_count = 0
        skipped_count = 0

        # ê° í–‰ ì²˜ë¦¬
        for i in range(len(data['Prompt UID'])):
            try:
                prompt_uid = data['Prompt UID'][i]
                title = data['Title'][i]
                content = data['Content'][i]
                language = data['Language'][i]
                public_available = True
                is_template = True

                # None ë˜ëŠ” ë¹ˆ ë¬¸ìì—´ ì²´í¬
                if not prompt_uid or not title or not content or not language:
                    logger.warning(f"âš ï¸  Skipping row {i+1}: Missing required data")
                    skipped_count += 1
                    continue

                # Prompt ê°ì²´ ìƒì„±
                new_prompt = Prompts(
                    user_id=None,
                    prompt_uid=str(prompt_uid).strip(),
                    prompt_title=str(title).strip(),
                    prompt_content=str(content).strip(),
                    public_available=public_available,
                    is_template=is_template,
                    language=str(language).strip(),
                    metadata=None
                )

                # ì¤‘ë³µ ì²´í¬ (prompt_uid ê¸°ì¤€)
                existing = app_db.find_by_condition(
                    Prompts,
                        {"prompt_uid": new_prompt.prompt_uid},
                    limit=1
                )

                if not existing or len(existing) == 0:
                    result = app_db.insert(new_prompt)
                    if result and result.get("result") == "success":
                        inserted_count += 1
                        logger.debug(f"âœ… Inserted prompt: {new_prompt.prompt_uid} ({new_prompt.language})")
                    else:
                        skipped_count += 1
                        logger.warning(f"âš ï¸  Failed to insert prompt {i+1}: {new_prompt.prompt_uid}")
                else:
                    skipped_count += 1
                    logger.debug(f"ğŸ”„ Skipped existing prompt: {new_prompt.prompt_uid}")

            except Exception as e:
                logger.warning(f"âš ï¸  Failed to process row {i+1}: {e}")
                skipped_count += 1
                continue

        logger.info(f"âœ… Successfully processed {inserted_count + skipped_count} prompt records")
        logger.info(f"ğŸ“ Inserted: {inserted_count}, Skipped: {skipped_count}")
        return {"success": True, "inserted_count": inserted_count, "skipped_count": skipped_count}

    except Exception as e:
        error_msg = f"Error loading prompts from CSV: {e}"
        logger.error(f"âŒ {error_msg}")
        return {"success": False, "error": error_msg}

def load_workflow_templates(app_db, templates_dir: str):
    """
    JSON íŒŒì¼ì—ì„œ ì›Œí¬í”Œë¡œìš° ìŠ¤í† ì–´ í…œí”Œë¦¿ì„ ë¡œë“œí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    try:
        # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
        if not Path(templates_dir).exists():
            logger.warning(f"âš ï¸  Workflow templates directory not found: {templates_dir}")
            return {"success": False, "error": "Templates directory not found"}

        # ì´ë¯¸ í…œí”Œë¦¿ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_templates = app_db.find_by_condition(WorkflowStoreMeta, {"is_template": True}, limit=1)
        if existing_templates and len(existing_templates) > 0:
            logger.info(f"âš ï¸  Workflow templates already exist in database ({len(existing_templates)} records). Skipping template import.")
            return {"success": True, "inserted_count": 0, "skipped": True, "message": "Templates already exist"}

        # JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        json_files = list(Path(templates_dir).glob("*.json"))
        if not json_files:
            logger.warning(f"âš ï¸  No JSON files found in: {templates_dir}")
            return {"success": False, "error": "No template files found"}

        logger.info(f"ğŸ“„ Found {len(json_files)} workflow template files")

        inserted_count = 0
        skipped_count = 0

        for json_file in json_files:
            try:
                # JSON íŒŒì¼ ì½ê¸° ë° ì „ì²˜ë¦¬
                with open(json_file, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)

                # JSONì„ ë‹¤ì‹œ íŒŒì‹±í•˜ì—¬ ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì •ë¦¬
                # ensure_ascii=Falseë¡œ í•œê¸€ ë“±ì´ ì œëŒ€ë¡œ ì €ì¥ë˜ë„ë¡ í•¨
                workflow_data = json.loads(
                    json.dumps(workflow_data, ensure_ascii=False)
                )

                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                workflow_id = workflow_data.get('workflow_id')
                workflow_name = workflow_data.get('workflow_name')

                if not workflow_id or not workflow_name:
                    logger.warning(f"âš ï¸  Skipping {json_file.name}: Missing workflow_id or workflow_name")
                    skipped_count += 1
                    continue

                # description ì¶”ì¶œ (ì—†ìœ¼ë©´ workflow_name ì‚¬ìš©)
                description = workflow_data.get('description', workflow_name)

                # nodesì™€ edges ê°œìˆ˜ ê³„ì‚°
                nodes = workflow_data.get('nodes', [])
                edges = workflow_data.get('edges', [])
                node_count = len(nodes)
                edge_count = len(edges)

                # startnodeì™€ endnode ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                has_startnode = any(
                    node.get('data', {}).get('functionId') == 'startnode'
                    for node in nodes
                )
                has_endnode = any(
                    node.get('data', {}).get('functionId') == 'endnode'
                    for node in nodes
                )

                # is_completed íŒë‹¨ (startnodeì™€ endnodeê°€ ëª¨ë‘ ìˆê³ , ìµœì†Œ 1ê°œ ì´ìƒì˜ edgeê°€ ìˆìœ¼ë©´)
                is_completed = has_startnode and has_endnode and edge_count > 0

                # tags ì¶”ì¶œ (metadataì— ìˆì„ ìˆ˜ ìˆìŒ)
                tags = workflow_data.get('tags', [])
                if isinstance(tags, str):
                    tags = [tags]

                # WorkflowStoreMeta ê°ì²´ ìƒì„±
                new_template = WorkflowStoreMeta(
                    user_id=None,  # í…œí”Œë¦¿ì´ë¯€ë¡œ None
                    workflow_id=workflow_id,
                    workflow_name=workflow_name,
                    workflow_upload_name=workflow_name,
                    node_count=node_count,
                    edge_count=edge_count,
                    has_startnode=has_startnode,
                    has_endnode=has_endnode,
                    is_completed=is_completed,
                    metadata={},  # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ í•„ìš”í•˜ë©´ ì—¬ê¸°ì—
                    current_version=1.0,
                    latest_version=1.0,
                    is_template=True,
                    description=description,
                    tags=tags,
                    workflow_data=workflow_data  # ì „ì²´ JSON ë°ì´í„°
                )

                # ì¤‘ë³µ ì²´í¬ (workflow_id ê¸°ì¤€)
                existing = app_db.find_by_condition(
                    WorkflowStoreMeta,
                    {"workflow_id": workflow_id},
                    limit=1
                )

                if not existing or len(existing) == 0:
                    result = app_db.insert(new_template)
                    if result and result.get("result") == "success":
                        inserted_count += 1
                        logger.debug(f"âœ… Inserted workflow template: {workflow_name}")
                    else:
                        skipped_count += 1
                        logger.warning(f"âš ï¸  Failed to insert template: {workflow_name}")
                else:
                    skipped_count += 1
                    logger.debug(f"ğŸ”„ Skipped existing template: {workflow_name}")

            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸  Failed to parse JSON file {json_file.name}: {e}")
                skipped_count += 1
                continue
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to process template {json_file.name}: {e}")
                skipped_count += 1
                continue

        logger.info(f"âœ… Successfully processed {inserted_count + skipped_count} workflow template files")
        logger.info(f"ğŸ“ Inserted: {inserted_count}, Skipped: {skipped_count}")
        return {"success": True, "inserted_count": inserted_count, "skipped_count": skipped_count}

    except Exception as e:
        error_msg = f"Error loading workflow templates: {e}"
        logger.error(f"âŒ {error_msg}")
        return {"success": False, "error": error_msg}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    try:
        # âš ï¸ ì£¼ì˜: ì´ ìë™ ë³µêµ¬ëŠ” ê¸´ê¸‰ ìƒí™©ìš©ì…ë‹ˆë‹¤.
        # ì •ìƒì ìœ¼ë¡œëŠ” Step 7.6ì˜ ìë™ ë¡œë“œê°€ Managerë¥¼ ë³µì›í•©ë‹ˆë‹¤.
        # fix_existing_managersëŠ” Redis ë°ì´í„° ì†ìƒ ì‹œì—ë§Œ í•„ìš”í•©ë‹ˆë‹¤.
        try:
            from fix_existing_managers import recover_all_managers
            # recover_all_managers()  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™” (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)
            logger.info("â„¹ï¸  ê¸´ê¸‰ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (ì •ìƒ)")
        except Exception as e:
            logger.debug(f"ê¸´ê¸‰ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

        print_xgen_logo()
        logger.info("ğŸŒŸ Starting XGEN application lifespan...")

        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ë§Œ ë¨¼ì € ì´ˆê¸°í™”
        print_step_banner(1, "DATABASE INITIALIZATION", "Initializing core database configuration")
        logger.info("âš™ï¸  Step 1: Database configuration initialization starting...")

        database_config = config_composer.initialize_database_config_only()
        if not database_config:
            logger.error("âŒ Failed to initialize database configuration")
            return
        logger.info("âœ… Step 1: Database configuration initialized successfully!")

        # 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ëª¨ë“  ëª¨ë¸ í…Œì´ë¸” ìƒì„±)
        print_step_banner(2, "APPLICATION DATABASE SETUP", "Creating tables and running migrations")
        logger.info("âš™ï¸  Step 2: Application database initialization starting...")

        app_db = AppDatabaseManager(database_config)
        app_db.register_models(APPLICATION_MODELS)

        if app_db.initialize_database():
            app.state.app_db = app_db
            logger.info("âœ… Step 2: Application database initialized successfully!")

            # Run database migrations
            logger.info("ğŸ”„ Running database migrations...")
            if app_db.run_migrations():
                logger.info("âœ… Database migrations completed successfully!")
            else:
                logger.warning("âš ï¸  Database migrations failed, but continuing startup")
        else:
            logger.error("âŒ Failed to initialize application database")
            app.state.app_db = None
            return

        # 3. ë‚˜ë¨¸ì§€ ì„¤ì •ë“¤ ì´ˆê¸°í™” (ì´ì œ DB í…Œì´ë¸”ì´ ì¡´ì¬í•¨)
        print_step_banner(3, "CONFIGURATION SETUP", "Loading remaining system configurations")
        logger.info("âš™ï¸  Step 3: System configuration initialization starting...")

        configs = config_composer.initialize_remaining_configs()
        app.state.config_composer = config_composer
        logger.info("âœ… Step 3: System configurations loaded successfully!")

        # 4. RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë²¡í„° DBì™€ ì„ë² ë”© ì œê³µì)
        print_step_banner(4, "RAG SERVICES INITIALIZATION", "Setting up vector DB and embedding services")
        try:
            print_step_banner(4.1, "EMBEDDING SERVICE SETUP", "Setting up embedding services")
            embedding_client = EmbeddingFactory.create_embedding_client(config_composer)
            app.state.embedding_client = embedding_client

            print_step_banner(4.2, "VECTOR SERVICE SETUP", "Setting up vector services")
            vector_manager = VectorManager(config_composer)
            app.state.vector_manager = vector_manager

            print_step_banner(4.3, "DOCUMENT PROCESSOR SETUP", "Setting up document processing services")
            document_processor = DocumentProcessor(config_composer)
            app.state.document_processor = document_processor

            print_step_banner(4.4, "DOCUMENT INFO GENERATOR SETUP", "Setting up document info generation services")
            document_info_generator = DocumentInfoGenerator(config_composer)
            app.state.document_info_generator = document_info_generator
            logger.info("âœ… Step 4: RAG services components initialized successfully!")

        except Exception as e:
            logger.error(f"âŒ Step 4: Failed to initialize RAG services: {e}")
            # RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì€ ê³„ì†
            app.state.rag_service = None
            app.state.vector_manager = None
            app.state.embedding_client = None
            app.state.document_processor = None

        # 5. STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        if config_composer.get_config_by_name("IS_AVAILABLE_STT").value:
            print_step_banner(5, "STT SERVICE SETUP", "Setting up Speech-to-Text services")
            try:
                logger.info("âš™ï¸  Step 5: STT service initialization starting...")
                stt_client = STTFactory.create_stt_client(config_composer)
                app.state.stt_service = stt_client
                logger.info("âœ… Step 5: STT service initialized successfully!")
            except Exception as e:
                logger.error(f"âŒ Step 5: Failed to initialize STT service: {e}")
                # STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì€ ê³„ì†
                app.state.stt_service = None
        else:
            print_step_banner(5, "STT SERVICE SETUP", "STT service is disabled in configuration")
            app.state.stt_service = None

        # 5.5. TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        if config_composer.get_config_by_name("IS_AVAILABLE_TTS").value:
            print_step_banner(5.5, "TTS SERVICE SETUP", "Setting up Text-to-Speech services")
            try:
                logger.info("âš™ï¸  Step 5.5: TTS service initialization starting...")
                tts_client = TTSFactory.create_tts_client(config_composer)
                app.state.tts_service = tts_client
                logger.info("âœ… Step 5.5: TTS service initialized successfully!")
            except Exception as e:
                logger.error(f"âŒ Step 5.5: Failed to initialize TTS service: {e}")
                # TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì€ ê³„ì†
                app.state.tts_service = None
        else:
            print_step_banner(5.5, "TTS SERVICE SETUP", "TTS service is disabled in configuration")
            app.state.tts_service = None

        # 5.7. Guarder ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        if config_composer.get_config_by_name("IS_AVAILABLE_GUARDER").value:
            print_step_banner(5.7, "GUARDER SERVICE SETUP", "Setting up Text Moderation services")
            try:
                logger.info("âš™ï¸  Step 5.7: Guarder service initialization starting...")
                guarder_client = GuarderFactory.create_guarder_client(config_composer)
                app.state.guarder_service = guarder_client
                logger.info("âœ… Step 5.7: Guarder service initialized successfully!")
            except Exception as e:
                logger.error(f"âŒ Step 5.7: Failed to initialize Guarder service: {e}")
                # Guarder ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì€ ê³„ì†
                app.state.guarder_service = None
        else:
            print_step_banner(5.7, "GUARDER SERVICE SETUP", "Guarder service is disabled in configuration")
            app.state.guarder_service = None

        # 6. Vast proxy client ìƒì„±
        print_step_banner(6, "VAST PROXY SETUP", "Initializing remote VastAI proxy")
        logger.info("âš™ï¸  Step 6: VAST proxy client initialization starting...")
        vast_proxy_client = VastProxyClient(config_composer)
        app.state.vast_proxy_client = vast_proxy_client
        # ê¸°ì¡´ ì˜ì¡´ì„±ì„ ì‚¬ìš©í•˜ëŠ” ì½”ë“œ í˜¸í™˜ì„ ìœ„í•´ ë™ì¼ ê°ì²´ë¥¼ vast_serviceë¡œë„ ë…¸ì¶œ
        app.state.vast_service = vast_proxy_client
        logger.info("âœ… Step 6: VAST proxy client initialized successfully")

        # 7. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        print_step_banner(7, "WORKFLOW MANAGER SETUP", "Setting up workflow execution engine")
        logger.info("âš™ï¸  Step 7: Workflow execution manager initialization starting...")
        app.state.execution_manager = execution_manager
        logger.info("âœ… Step 7: Workflow execution manager initialized successfully!")

        print_step_banner(7.5, "DATA MANAGER REGISTRY SETUP", "Setting up data manager registry")
        logger.info("âš™ï¸  Step 7.5: Data manager registry initialization starting...")
        app.state.data_manager_registry = DataManagerRegistry(app_db_manager=app.state.app_db)
        logger.info("âœ… Step 7.5: Data manager registry initialized successfully!")

        # â­ 7.6. ì €ì¥ëœ ë§¤ë‹ˆì € ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        print_step_banner(7.6, "MANAGER METADATA INIT", "Initializing manager metadata (Lazy Loading)")
        logger.info("âš™ï¸  Step 7.6: Manager metadata initialization...")

        try:
            registry = app.state.data_manager_registry

            # ğŸ§¹ ê³ ì•„ Manager ìë™ ì •ë¦¬ (ì„ íƒ ì‚¬í•­)
            AUTO_CLEANUP_ORPHANED = os.getenv("AUTO_CLEANUP_ORPHANED_MANAGERS", "false").lower() == "true"

            if AUTO_CLEANUP_ORPHANED:
                logger.info("ğŸ§¹ ê³ ì•„ Manager ìë™ ì •ë¦¬ ì‹œì‘...")
                orphaned_count = 0
                orphaned_manager_ids = []

                cursor = 0
                all_manager_ids = set()

                # ëª¨ë“  Manager ID ìˆ˜ì§‘
                while True:
                    cursor, keys = registry.redis_manager.redis_client.scan(
                        cursor=cursor,
                        match="manager:*:*",
                        count=100
                    )
                    for key in keys:
                        if isinstance(key, bytes):
                            key = key.decode('utf-8')
                        parts = key.split(':')
                        if len(parts) >= 3:
                            all_manager_ids.add(parts[1])
                    if cursor == 0:
                        break

                # ê³ ì•„ Manager ì°¾ì•„ì„œ ì •ë¦¬
                for manager_id in all_manager_ids:
                    owner = registry.redis_manager.get_manager_owner(manager_id)
                    if not owner:
                        # Owner ì—†ìœ¼ë©´ ê´€ë ¨ í‚¤ ì „ë¶€ ì‚­ì œ
                        try:
                            patterns = [
                                f"manager:{manager_id}:owner",
                                f"manager:{manager_id}:dataset_id",
                                f"manager:{manager_id}:state",
                                f"manager:{manager_id}:created_at",
                                f"manager:{manager_id}:resource_stats",
                            ]
                            for pattern in patterns:
                                registry.redis_manager.redis_client.delete(pattern)
                            orphaned_manager_ids.append(manager_id)
                            orphaned_count += 1
                            logger.debug(f"  â””â”€ ğŸ—‘ï¸  ê³ ì•„ Manager ì‚­ì œ: {manager_id}")
                        except Exception as e:
                            logger.warning(f"  â””â”€ âš ï¸  ì‚­ì œ ì‹¤íŒ¨: {manager_id} - {e}")

                # DB Sync Configì—ì„œë„ ì •ë¦¬
                if orphaned_manager_ids:
                    try:
                        from service.database.models.db_sync_config import DBSyncConfig
                        deleted_db_configs = 0
                        for manager_id in orphaned_manager_ids:
                            configs = app.state.app_db.find_by_condition(
                                DBSyncConfig,
                                {'manager_id': manager_id},
                                limit=10
                            )
                            for config in configs:
                                app.state.app_db.delete(DBSyncConfig, config.id)
                                deleted_db_configs += 1

                        if deleted_db_configs > 0:
                            logger.info(f"  â””â”€ ğŸ—‘ï¸  DB Sync Config {deleted_db_configs}ê°œ ì •ë¦¬")
                    except Exception as e:
                        logger.warning(f"  â””â”€ âš ï¸  DB Sync Config ì •ë¦¬ ì‹¤íŒ¨: {e}")

                if orphaned_count > 0:
                    logger.info(f"  â””â”€ ğŸ§¹ ê³ ì•„ Manager {orphaned_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
                else:
                    logger.info(f"  â””â”€ âœ… ê³ ì•„ Manager ì—†ìŒ")

            # Redisì—ì„œ ìœ íš¨í•œ ë§¤ë‹ˆì € ìˆ˜ í™•ì¸
            cursor = 0
            valid_manager_ids = set()

            while True:
                cursor, keys = registry.redis_manager.redis_client.scan(
                    cursor=cursor,
                    match="manager:*:owner",
                    count=100
                )

                for key in keys:
                    if isinstance(key, bytes):
                        key = key.decode('utf-8')

                    parts = key.split(':')
                    if len(parts) >= 3:
                        manager_id = parts[1]
                        valid_manager_ids.add(manager_id)

                if cursor == 0:
                    break

            logger.info(f"âœ… Step 7.6: ë°œê²¬ëœ ë§¤ë‹ˆì €: {len(valid_manager_ids)}ê°œ")
            logger.info(f"  â””â”€ ğŸ’¡ Lazy Loading ì „ëµ: API í˜¸ì¶œ ì‹œ ìë™ ë³µì›ë©ë‹ˆë‹¤")
            logger.info(f"  â””â”€ ìë™ ë³µì› ê²½ë¡œ: DataManagerRegistry.get_manager()")

        except Exception as e:
            logger.error(f"âŒ Step 7.6: ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        # 7.7. MLflow artifact service initialization
        print_step_banner(7.7, "MLFLOW ARTIFACT SERVICE", "Integrating MLflow tracking and artifacts")
        mlflow_tracking_uri = os.getenv("MLFLOW_URL", "").strip()
        mlflow_default_experiment_id = os.getenv("MLFLOW_DEFAULT_EXPERIMENT_ID")
        mlflow_cache_dir = os.getenv("MLFLOW_CACHE_DIR")
        mlflow_token = os.getenv("MLFLOW_TRACKING_TOKEN")

        if mlflow_tracking_uri:
            try:
                logger.info("âš™ï¸  Step 7.7: MLflow artifact service initialization starting...")
                mlflow_service = MLflowArtifactService(
                    tracking_uri=mlflow_tracking_uri,
                    default_experiment_id=mlflow_default_experiment_id,
                    cache_dir=mlflow_cache_dir,
                    tracking_token=mlflow_token,
                )
                app.state.mlflow_service = mlflow_service
                logger.info("âœ… Step 7.7: MLflow artifact service initialized successfully!")
            except Exception as mlflow_error:
                app.state.mlflow_service = None
                logger.error(
                    "âŒ Step 7.7: Failed to initialize MLflow service: %s",
                    mlflow_error,
                    exc_info=True,
                )
        else:
            app.state.mlflow_service = None
            logger.warning("âš ï¸  MLflow tracking URI not configured. MLflow integration is disabled.")

        # 7.8. DB Sync Scheduler ì´ˆê¸°í™”
        print_step_banner(7.8, "DB SYNC SCHEDULER SETUP", "Setting up database synchronization scheduler")
        logger.info("âš™ï¸  Step 7.8: DB Sync Scheduler initialization starting...")

        try:
            from controller.helper.singletonHelper import initialize_db_sync_scheduler

            # ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
            db_sync_scheduler = initialize_db_sync_scheduler(app.state)

            logger.info(f"âœ… Step 7.8: DB Sync Scheduler initialized successfully!")
            logger.info(f"  â””â”€ Scheduler running: {db_sync_scheduler.scheduler.running}")
            logger.info(f"  â””â”€ Loaded sync configs: {len(db_sync_scheduler.sync_configs)}")

        except Exception as e:
            logger.error(f"âŒ Step 7.8: Failed to initialize DB Sync Scheduler: {e}", exc_info=True)
            app.state.db_sync_scheduler = None
            logger.warning("âš ï¸  DB Sync Scheduler is disabled. Sync endpoints will not be available.")

        print_step_banner(8, "SYSTEM VALIDATION", "Validating configurations and directories")
        logger.info("âš™ï¸  Step 8: System validation starting...")

        config_composer.ensure_directories()
        validation_result = config_composer.validate_critical_configs()
        if not validation_result["valid"]:
            for error in validation_result["errors"]:
                logger.error(f"âŒ Configuration error: {error}")
        for warning in validation_result["warnings"]:
            logger.warning(f"âš ï¸  Configuration warning: {warning}")
        logger.info("âœ… Step 8: System validation completed!")

        # 9. ì›Œí¬í”Œë¡œìš° ë°ì´í„° ë™ê¸°í™”
        print_step_banner(9, "WORKFLOW DATA SYNC", "Synchronizing workflow filesystem and database")
        logger.info("âš™ï¸  Step 9: Workflow data synchronization starting...")

        try:
            logger.info("ğŸ”„ Step 9: SKIPPED - Workflow data sync is currently disabled")
            # sync_result = await workflow_data_synchronizer(app.state.app_db)
            # if sync_result["success"]:
            #     logger.info(f"âœ… Step 9: Workflow data sync completed successfully! "
            #                f"Added {sync_result['files_added_to_db']} to DB, "
            #                f"Created {sync_result['files_created_from_db']} files, "
            #                f"Removed {sync_result['orphaned_db_entries_removed']} orphaned entries, "
            #                f"Processed {sync_result['users_processed']} users")
            # else:
            #     logger.warning(f"âš ï¸  Step 9: Workflow data sync completed with issues. "
            #                  f"Errors: {sync_result.get('errors', [])}")
        except Exception as e:
            logger.error(f"âŒ Step 9: Failed to sync workflow data: {e}")

        # 9.5. ì›Œí¬í”Œë¡œìš°-ë°°í¬ ë©”íƒ€ë°ì´í„° ë™ê¸°í™”
        print_step_banner(9.5, "WORKFLOW-DEPLOY SYNC", "Synchronizing workflow and deploy metadata")
        logger.info("âš™ï¸  Step 9.5: Workflow-deploy metadata synchronization starting...")

        try:
            sync_result = sync_workflow_deploy_meta(app.state.app_db)
            if sync_result["success"]:
                logger.info(f"âœ… Step 9.5: Workflow-deploy sync completed successfully! "
                           f"Created {sync_result['created_deploys']} new deploy entries from "
                           f"{sync_result['total_workflows']} total workflows")
            else:
                logger.warning(f"âš ï¸  Step 9.5: Workflow-deploy sync completed with issues. "
                             f"Errors: {sync_result.get('errors', [])}")
        except Exception as e:
            logger.error(f"âŒ Step 9.5: Failed to sync workflow-deploy metadata: {e}")

        print_step_banner(10, "NODE DISCOVERY", "Discovering and registering XGEN nodes")
        logger.info("âš™ï¸  Step 10: Node discovery starting...")

        run_discovery()
        registry_path = configs["node"].REGISTRY_FILE_PATH.value
        generate_json_spec(registry_path)
        app.state.node_registry = get_node_registry()
        app.state.node_count = len(app.state.node_registry)

        # ë…¸ë“œ API ë¼ìš°íŠ¸ ë“±ë¡
        logger.info("ğŸ”— Registering node API routes...")
        register_node_api_routes()
        logger.info("âœ… Node API routes registered successfully!")

        logger.info(f"âœ… Step 10: Node discovery completed! Registered {app.state.node_count} nodes")

        # 11. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë°ì´í„° ë¡œë“œ
        print_step_banner(11, "PROMPT TEMPLATES LOADING", "Loading prompt templates from CSV to database")
        logger.info("âš™ï¸  Step 11: Prompt templates loading starting...")

        try:
            constants_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "constants")
            prompts_csv_path = os.path.join(constants_dir, "prompts_processed.csv")
            load_result = load_prompts_from_csv(app.state.app_db, prompts_csv_path)

            if load_result["success"]:
                if load_result.get("skipped", False):
                    logger.info(f"âœ… Step 11: Prompt templates already exist - skipped loading")
                else:
                    inserted = load_result.get("inserted_count", 0)
                    skipped = load_result.get("skipped_count", 0)
                    logger.info(f"âœ… Step 11: Prompt templates loaded successfully! "
                               f"Inserted: {inserted}, Skipped: {skipped}")
            else:
                logger.warning(f"âš ï¸  Step 11: Prompt templates loading completed with issues. "
                             f"Error: {load_result.get('error', 'Unknown error')}")
        except Exception as e:
            logger.error(f"âŒ Step 11: Failed to load prompt templates: {e}")

        # 12. ì›Œí¬í”Œë¡œìš° ìŠ¤í† ì–´ í…œí”Œë¦¿ ë¡œë“œ
        print_step_banner(12, "WORKFLOW STORE TEMPLATES", "Loading workflow store templates from JSON files")
        logger.info("âš™ï¸  Step 12: Workflow store templates loading starting...")

        try:
            constants_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "constants")
            templates_dir = os.path.join(constants_dir, "workflow_store_template")
            load_result = load_workflow_templates(app.state.app_db, templates_dir)

            if load_result["success"]:
                if load_result.get("skipped", False):
                    logger.info(f"âœ… Step 12: Workflow store templates already exist - skipped loading")
                else:
                    inserted = load_result.get("inserted_count", 0)
                    skipped = load_result.get("skipped_count", 0)
                    logger.info(f"âœ… Step 12: Workflow store templates loaded successfully! "
                               f"Inserted: {inserted}, Skipped: {skipped}")
            else:
                logger.warning(f"âš ï¸  Step 12: Workflow store templates loading completed with issues. "
                             f"Error: {load_result.get('error', 'Unknown error')}")
        except Exception as e:
            logger.error(f"âŒ Step 12: Failed to load workflow store templates: {e}")

        print_step_banner("FINAL", "XGEN STARTUP COMPLETE", "All systems operational! ğŸ‰")
        logger.info("ğŸ‰ XGEN application startup complete! Ready to serve requests.")

        # SSE ì„¸ì…˜ ê´€ë¦¬ì ìë™ ì •ë¦¬ íƒœìŠ¤í¬ ì‹œì‘
        print_step_banner("SSE", "SSE SESSION MANAGER", "Starting SSE session cleanup task")
        logger.info("âš™ï¸  SSE Session Manager: Starting cleanup task...")
        try:
            from service.retrieval.sse_session_manager import sse_session_manager
            sse_session_manager.start_cleanup_task(interval_minutes=10)
            logger.info("âœ… SSE Session Manager: Cleanup task started (10 min interval)")
        except Exception as e:
            logger.error(f"âŒ SSE Session Manager: Failed to start cleanup task: {e}")

    except Exception as e:
        logger.error(f"ğŸ’¥ Error during startup: {e}")
        logger.info("ğŸ”„ Application will continue despite startup error")

    yield

    logger.info("ğŸ›‘ XGEN application shutdown...")
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                XGEN SHUTDOWN                        â”‚
    â”‚           Gracefully stopping all services         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    try:
        # SSE ì„¸ì…˜ ê´€ë¦¬ì ì •ë¦¬
        try:
            from service.retrieval.sse_session_manager import sse_session_manager
            logger.info("ğŸ”„ Stopping SSE session manager cleanup task...")
            sse_session_manager.stop_cleanup_task()
            logger.info("âœ… SSE session manager cleanup task stopped")
        except Exception as e:
            logger.error(f"âŒ Failed to stop SSE session manager: {e}")

        if hasattr(app.state, 'db_sync_scheduler') and app.state.db_sync_scheduler:
            logger.info("ğŸ”„ Shutting down DB Sync Scheduler...")
            from controller.helper.singletonHelper import shutdown_db_sync_scheduler
            shutdown_db_sync_scheduler(app.state)
            logger.info("âœ… DB Sync Scheduler shutdown complete")
        # Data Manager Registry ì •ë¦¬
        if hasattr(app.state, 'data_manager_registry') and app.state.data_manager_registry:
            logger.info("ğŸ”„ Cleaning up data manager registry...")
            app.state.data_manager_registry.cleanup()
            logger.info("âœ… Data manager registry cleanup complete")

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë§¤ë‹ˆì € ì •ë¦¬
        if hasattr(app.state, 'execution_manager') and app.state.execution_manager:
            logger.info("ğŸ”„ Shutting down workflow execution manager...")
            app.state.execution_manager.shutdown()
            logger.info("âœ… Workflow execution manager shutdown complete")

        # STT ì„œë¹„ìŠ¤ ì •ë¦¬
        if hasattr(app.state, 'stt_service') and app.state.stt_service:
            logger.info("ğŸ”„ Cleaning up STT service...")
            await app.state.stt_service.cleanup()
            logger.info("âœ… STT service cleanup complete")

        # TTS ì„œë¹„ìŠ¤ ì •ë¦¬
        if hasattr(app.state, 'tts_service') and app.state.tts_service:
            logger.info("ğŸ”„ Cleaning up TTS service...")
            await app.state.tts_service.cleanup()
            logger.info("âœ… TTS service cleanup complete")

        # Guarder ì„œë¹„ìŠ¤ ì •ë¦¬
        if hasattr(app.state, 'guarder_service') and app.state.guarder_service:
            logger.info("ğŸ”„ Cleaning up Guarder service...")
            await app.state.guarder_service.cleanup()
            logger.info("âœ… Guarder service cleanup complete")

        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬
        if hasattr(app.state, 'app_db') and app.state.app_db:
            app.state.app_db.close()
            logger.info("âœ… Application database connection closed")

        config_composer.save_all()
        logger.info("âœ… Configurations saved on shutdown")
        logger.info("ğŸ‘‹ XGEN shutdown complete. Goodbye!")
    except Exception as e:
        logger.error(f"ğŸ’¥ Error during shutdown: {e}")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("plateerag-backend")

app = FastAPI(
    title="PlateeRAG Backend",
    description="API for training models with customizable parameters - Enhanced with app.state",
    version="1.0.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹œì‘ì‹œ ê¸°ë³¸ê°’, config ë¡œë“œ í›„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(node_router)
app.include_router(admin_router)
app.include_router(workflow_router)
app.include_router(auto_generation_router)
app.include_router(rag_router)
app.include_router(audio_router)
app.include_router(data_manager_router)
app.include_router(model_router)
app.include_router(tool_router)

app.include_router(authRouter)
app.include_router(llmRouter)
app.include_router(performanceRouter)
app.include_router(trainRouter)
app.include_router(interactionRouter)
app.include_router(appRouter)
app.include_router(vastProxyRouter)
app.include_router(huggingfaceRouter)
app.include_router(promptRouter)
app.include_router(mcpRouter)

if __name__ == "__main__":
    try:
        host = os.environ.get("APP_HOST", "0.0.0.0")
        port = int(os.environ.get("APP_PORT", "8000"))
        debug = os.environ.get("DEBUG_MODE", "false").lower() in ('true', '1', 'yes', 'on')

        print(f"Starting server on {host}:{port} (debug={debug})")
        if debug:
            uvicorn.run("main:app", host=host, port=port, reload=True)
        else:
            uvicorn.run("main:app", host=host, port=port, reload=False)
    except Exception as e:
        logger.warning(f"Failed to load config for uvicorn: {e}")
        logger.info("Using default values for uvicorn")
        uvicorn.run("main:app", host="0.0.0.0", port=10, reload=False)
