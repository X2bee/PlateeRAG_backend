"""
VastAI ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ ì»¨íŠ¸ë¡¤ëŸ¬

VastAI í´ë¼ìš°ë“œ GPU ì¸ìŠ¤í„´ìŠ¤ì˜ ê²€ìƒ‰, ìƒì„±, ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ RESTful API
"""

from fastapi import APIRouter, HTTPException, Request, BackgroundTasks, Query
from pydantic import BaseModel, Field
import logging
from typing import Dict, Any, Optional, List, Literal
from enum import Enum
import json

from service.vast.vast_service import VastService, auto_run_vllm

router = APIRouter(prefix="/api/vast", tags=["vastAI"])
logger = logging.getLogger("vast-controller")

# ========== Enums ==========
class SortBy(str, Enum):
    price = "price"
    gpu_ram = "gpu_ram"
    num_gpus = "num_gpus"

class VLLMDtype(str, Enum):
    auto = "auto"
    half = "half"
    float16 = "float16"
    bfloat16 = "bfloat16"
    float = "float"
    float32 = "float32"

class ToolCallParser(str, Enum):
    hermes = "hermes"
    mistral = "mistral"
    none = "none"

# ========== Request Models ==========
class OfferSearchRequest(BaseModel):
    """GPU ì˜¤í¼ ê²€ìƒ‰ ìš”ì²­"""
    gpu_name: Optional[str] = Field(None, description="GPU ëª¨ë¸ëª…", example="RTX4090")
    max_price: Optional[float] = Field(None, description="ìµœëŒ€ ì‹œê°„ë‹¹ ê°€ê²© ($)", example=2.0, ge=0)
    min_gpu_ram: Optional[int] = Field(None, description="ìµœì†Œ GPU RAM (GB)", example=16, ge=1)
    num_gpus: Optional[int] = Field(None, description="GPU ê°œìˆ˜", example=1, ge=1)
    rentable: Optional[bool] = Field(None, description="ë ŒíŠ¸ ê°€ëŠ¥ ì—¬ë¶€", example=True)
    sort_by: SortBy = Field(SortBy.price, description="ì •ë ¬ ê¸°ì¤€")
    limit: Optional[int] = Field(20, description="ê²°ê³¼ ì œí•œ ê°œìˆ˜", example=10, ge=1, le=100)

class VLLMConfigRequest(BaseModel):
    """VLLM ì„¤ì • ìš”ì²­"""
    # ëª¨ë¸ ì„¤ì •
    vllm_model_name: str = Field("Qwen/Qwen3-1.7B", description="ì‚¬ìš©í•  ëª¨ë¸ëª…", example="Qwen/Qwen3-1.7B")
    vllm_max_model_len: int = Field(4096, description="ìµœëŒ€ ëª¨ë¸ ê¸¸ì´", example=2048, ge=512, le=32768)

    # ë„¤íŠ¸ì›Œí¬ ì„¤ì •
    vllm_host_ip: str = Field("0.0.0.0", description="í˜¸ìŠ¤íŠ¸ IP", example="0.0.0.0")
    vllm_port: int = Field(11479, description="VLLM ì„œë¹„ìŠ¤ í¬íŠ¸", example=12434, ge=1024, le=65535)
    vllm_controller_port: int = Field(11480, description="VLLM ì»¨íŠ¸ë¡¤ëŸ¬ í¬íŠ¸", example=12435, ge=1024, le=65535)

    # ì„±ëŠ¥ ì„¤ì •
    vllm_gpu_memory_utilization: float = Field(0.9, description="GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", example=0.5, ge=0.1, le=1.0)
    vllm_pipeline_parallel_size: int = Field(1, description="íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ í¬ê¸°", example=1, ge=1)
    vllm_tensor_parallel_size: int = Field(1, description="í…ì„œ ë³‘ë ¬ í¬ê¸°", example=1, ge=1)

    # ë°ì´í„° íƒ€ì… ë° ê³ ê¸‰ ì„¤ì •
    vllm_dtype: VLLMDtype = Field(VLLMDtype.auto, description="ë°ì´í„° íƒ€ì…")
    vllm_tool_call_parser: Optional[ToolCallParser] = Field(None, description="ë„êµ¬ í˜¸ì¶œ íŒŒì„œ")
    vllm_trust_remote_code: bool = Field(True, description="ì›ê²© ì½”ë“œ ì‹ ë¢° ì—¬ë¶€")
    vllm_enforce_eager: bool = Field(False, description="ì¦‰ì‹œ ì‹¤í–‰ ê°•ì œ ì—¬ë¶€")
    vllm_max_num_seqs: Optional[int] = Field(None, description="ìµœëŒ€ ì‹œí€€ìŠ¤ ìˆ˜", ge=1)
    vllm_block_size: int = Field(16, description="ë¸”ë¡ í¬ê¸°", example=16, ge=1)
    vllm_swap_space: int = Field(4, description="ìŠ¤ì™‘ ê³µê°„ (GiB)", example=4, ge=0)
    vllm_disable_log_stats: bool = Field(False, description="ë¡œê·¸ í†µê³„ ë¹„í™œì„±í™”")

class CreateInstanceRequest(BaseModel):
    """ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ìš”ì²­"""
    offer_id: Optional[str] = Field(None, description="íŠ¹ì • ì˜¤í¼ ID (ì—†ìœ¼ë©´ ìë™ ì„ íƒ)", example="12345")
    hf_hub_token: Optional[str] = Field(None, description="HuggingFace í† í°", example="hf_xxxxx")
    template_name: Optional[str] = Field(None, description="ì‚¬ìš©í•  í…œí”Œë¦¿ ì´ë¦„ (budget, high_performance, research)", example="budget")
    auto_destroy: Optional[bool] = Field(None, description="ìë™ ì‚­ì œ ì—¬ë¶€", example=False)
    vllm_config: Optional[VLLMConfigRequest] = Field(None, description="VLLM ì„¤ì • (ì„ íƒì‚¬í•­)")

class SetupVLLMRequest(BaseModel):
    """VLLM ì„¤ì • ë° ì‹¤í–‰ ìš”ì²­"""
    script_directory: str = Field("/vllm/vllm-script", description="ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    hf_hub_token: Optional[str] = Field(None, description="HuggingFace í† í°", example="hf_xxxxx")
    main_script: str = Field("main.py", description="ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ëª…")
    log_file: str = Field("/tmp/vllm.log", description="ë¡œê·¸ íŒŒì¼ ê²½ë¡œ")
    install_requirements: bool = Field(True, description="requirements.txt ì„¤ì¹˜ ì—¬ë¶€")
    vllm_config: VLLMConfigRequest = Field(..., description="VLLM ì„¤ì •")
    additional_env_vars: Optional[Dict[str, str]] = Field(None, description="ì¶”ê°€ í™˜ê²½ë³€ìˆ˜")

class ExecuteCommandRequest(BaseModel):
    """ëª…ë ¹ì–´ ì‹¤í–‰ ìš”ì²­"""
    command: str = Field(..., description="ì‹¤í–‰í•  ëª…ë ¹ì–´", example="ps aux | grep python")
    working_directory: Optional[str] = Field(None, description="ì‘ì—… ë””ë ‰í† ë¦¬", example="/vllm/vllm-script")
    environment_vars: Optional[Dict[str, str]] = Field(None, description="í™˜ê²½ë³€ìˆ˜")
    background: bool = Field(False, description="ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì—¬ë¶€")
    timeout: Optional[int] = Field(300, description="íƒ€ì„ì•„ì›ƒ (ì´ˆ)", ge=1, le=3600)

# ========== Response Models ==========
class OfferInfo(BaseModel):
    """GPU ì˜¤í¼ ì •ë³´"""
    id: str = Field(..., description="ì˜¤í¼ ID")
    gpu_name: str = Field(..., description="GPU ëª¨ë¸ëª…")
    num_gpus: int = Field(..., description="GPU ê°œìˆ˜")
    gpu_ram: float = Field(..., description="GPU RAM (GB)")
    dph_total: float = Field(..., description="ì‹œê°„ë‹¹ ì´ ê°€ê²© ($)")
    rentable: bool = Field(..., description="ë ŒíŠ¸ ê°€ëŠ¥ ì—¬ë¶€")
    public_ipaddr: Optional[str] = Field(None, description="ê³µê°œ IP ì£¼ì†Œ")

class OfferSearchResponse(BaseModel):
    """GPU ì˜¤í¼ ê²€ìƒ‰ ì‘ë‹µ"""
    offers: List[OfferInfo] = Field(..., description="ê²€ìƒ‰ëœ ì˜¤í¼ ëª©ë¡")
    total: int = Field(..., description="ì „ì²´ ì˜¤í¼ ìˆ˜")
    filtered_count: int = Field(..., description="í•„í„°ë§ëœ ì˜¤í¼ ìˆ˜")
    search_query: Optional[str] = Field(None, description="ì‚¬ìš©ëœ ê²€ìƒ‰ ì¿¼ë¦¬")
    sort_info: Dict[str, str] = Field(..., description="ì •ë ¬ ì •ë³´")

class InstanceStatusResponse(BaseModel):
    """ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ì‘ë‹µ"""
    instance_id: str = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ID")
    status: str = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ")
    public_ip: Optional[str] = Field(None, description="ê³µê°œ IP")
    urls: Dict[str, str] = Field(default_factory=dict, description="ì ‘ê·¼ URLë“¤")
    port_mappings: Dict[str, Any] = Field(default_factory=dict, description="í¬íŠ¸ ë§¤í•‘")
    gpu_info: Optional[Dict[str, Any]] = Field(None, description="GPU ì •ë³´")
    cost_per_hour: Optional[float] = Field(None, description="ì‹œê°„ë‹¹ ë¹„ìš©")
    uptime: Optional[str] = Field(None, description="ê°€ë™ ì‹œê°„")
    vllm_status: Optional[Dict[str, Any]] = Field(None, description="VLLM ìƒíƒœ")

class InstanceListResponse(BaseModel):
    """ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì‘ë‹µ"""
    instances: List[Dict[str, Any]] = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡")
    total: int = Field(..., description="ì´ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜")

class CommandExecutionResponse(BaseModel):
    """ëª…ë ¹ì–´ ì‹¤í–‰ ì‘ë‹µ"""
    success: bool = Field(..., description="ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€")
    instance_id: str = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ID")
    command: str = Field(..., description="ì‹¤í–‰ëœ ëª…ë ¹ì–´")
    stdout: str = Field(..., description="í‘œì¤€ ì¶œë ¥")
    stderr: str = Field(..., description="í‘œì¤€ ì—ëŸ¬")
    background: bool = Field(..., description="ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì—¬ë¶€")
    error: Optional[str] = Field(None, description="ì—ëŸ¬ ë©”ì‹œì§€")

# ========== Helper Functions ==========
def get_vast_service(request: Request) -> VastService:
    """VastService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        config_composer = request.app.state.config_composer
        vast_config = config_composer.get_config_by_category_name("vast")
        db_manager = request.app.state.app_db
        return VastService(vast_config, db_manager)
    except Exception as e:
        logger.error(f"VastService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="VastService ì´ˆê¸°í™” ì‹¤íŒ¨")

def generate_vllm_env_vars(config: VLLMConfigRequest, hf_token: Optional[str] = None) -> Dict[str, str]:
    """VLLM í™˜ê²½ë³€ìˆ˜ ìƒì„±"""
    env_vars = {
        "VLLM_MODEL_NAME": config.vllm_model_name,
        "VLLM_HOST_IP": config.vllm_host_ip,
        "VLLM_PORT": str(config.vllm_port),
        "VLLM_CONTROLLER_PORT": str(config.vllm_controller_port),
        "VLLM_MAX_MODEL_LEN": str(config.vllm_max_model_len),
        "VLLM_GPU_MEMORY_UTILIZATION": str(config.vllm_gpu_memory_utilization),
        "VLLM_PIPELINE_PARALLEL_SIZE": str(config.vllm_pipeline_parallel_size),
        "VLLM_TENSOR_PARALLEL_SIZE": str(config.vllm_tensor_parallel_size),
        "VLLM_DTYPE": config.vllm_dtype,
        "VLLM_TRUST_REMOTE_CODE": str(config.vllm_trust_remote_code).lower(),
        "VLLM_ENFORCE_EAGER": str(config.vllm_enforce_eager).lower(),
        "VLLM_BLOCK_SIZE": str(config.vllm_block_size),
        "VLLM_SWAP_SPACE": str(config.vllm_swap_space),
        "VLLM_DISABLE_LOG_STATS": str(config.vllm_disable_log_stats).lower()
    }

    if config.vllm_tool_call_parser:
        env_vars["VLLM_TOOL_CALL_PARSER"] = config.vllm_tool_call_parser
    if config.vllm_max_num_seqs:
        env_vars["VLLM_MAX_NUM_SEQS"] = str(config.vllm_max_num_seqs)
    if hf_token:
        env_vars.update({
            "HUGGING_FACE_HUB_TOKEN": hf_token,
            "HF_HUB_TOKEN": hf_token
        })

    return env_vars

# ========== API Endpoints ==========

@router.get("/health",
    summary="ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸",
    description="VastAI ì„œë¹„ìŠ¤ì˜ ìƒíƒœì™€ ì—°ê²°ì„ í™•ì¸í•©ë‹ˆë‹¤.",
    response_description="ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´",
    responses={
        200: {"description": "ì„œë¹„ìŠ¤ ì •ìƒ"},
        503: {"description": "ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€"}
    })
async def health_check(request: Request):
    try:
        service = get_vast_service(request)
        return {
            "status": "healthy",
            "service": "vast",
            "message": "VastAI ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤"
        }
    except Exception as e:
        logger.error(f"Health check ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=503, detail="ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€")

@router.post("/search-offers",
    summary="GPU ì˜¤í¼ ê²€ìƒ‰",
    description="ì‚¬ìš© ê°€ëŠ¥í•œ VastAI GPU ì˜¤í¼ë¥¼ ê²€ìƒ‰í•˜ê³  í•„í„°ë§í•©ë‹ˆë‹¤. ê°€ê²©, GPU ì‚¬ì–‘, ê°€ìš©ì„± ë“±ìœ¼ë¡œ í•„í„°ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    response_model=OfferSearchResponse,
    responses={
        400: {"description": "API í‚¤ ì„¤ì • ì˜¤ë¥˜"},
        500: {"description": "ê²€ìƒ‰ ì‹¤íŒ¨"}
    })
async def search_offers(request: Request, search_request: OfferSearchRequest) -> OfferSearchResponse:
    try:
        service = get_vast_service(request)

        if not service.vast_manager.setup_api_key():
            raise HTTPException(status_code=400, detail="API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")

        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        query_parts = []
        if search_request.gpu_name:
            query_parts.append(f"gpu_name={search_request.gpu_name}")
        if search_request.max_price:
            query_parts.append(f"dph_total<={search_request.max_price}")
        if search_request.min_gpu_ram:
            query_parts.append(f"gpu_ram>={search_request.min_gpu_ram}")
        if search_request.num_gpus:
            query_parts.append(f"num_gpus={search_request.num_gpus}")
        if search_request.rentable is not None:
            query_parts.append(f"rentable={str(search_request.rentable).lower()}")

        search_query = " ".join(query_parts) if query_parts else None
        offers = service.vast_manager.search_offers(search_query)

        if not offers:
            return OfferSearchResponse(
                offers=[],
                total=0,
                filtered_count=0,
                search_query=search_query,
                sort_info={"sort_by": search_request.sort_by, "order": "ascending"}
            )

        # ì •ë ¬ ë° ì œí•œ
        sort_key_map = {"price": "dph_total", "gpu_ram": "gpu_ram", "num_gpus": "num_gpus"}
        sort_key = sort_key_map.get(search_request.sort_by, "dph_total")
        sorted_offers = sorted(offers, key=lambda x: x.get(sort_key, 999))
        limited_offers = sorted_offers[:search_request.limit] if search_request.limit else sorted_offers

        return OfferSearchResponse(
            offers=[OfferInfo(**offer) for offer in limited_offers],
            total=len(offers),
            filtered_count=len(limited_offers),
            search_query=search_query,
            sort_info={"sort_by": search_request.sort_by, "sort_key": sort_key, "order": "ascending"}
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì˜¤í¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì˜¤í¼ ê²€ìƒ‰ ì‹¤íŒ¨")

@router.post("/instances",
    summary="ì¸ìŠ¤í„´ìŠ¤ ìƒì„±",
    description="ìƒˆë¡œìš´ VastAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. í…œí”Œë¦¿ ì‚¬ìš©(budget, high_performance, research) ë˜ëŠ” ì»¤ìŠ¤í…€ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any],
    responses={
        400: {"description": "ì˜ëª»ëœ ìš”ì²­ (í…œí”Œë¦¿ ì—†ìŒ, ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ ë“±)"},
        500: {"description": "ì„œë²„ ì˜¤ë¥˜"}
    })
async def create_instance(request: Request, create_request: CreateInstanceRequest, background_tasks: BackgroundTasks):
    try:
        service = get_vast_service(request)

        # í…œí”Œë¦¿ ì ìš©
        if create_request.template_name:
            if create_request.template_name not in service.templates:
                available_templates = list(service.templates.keys())
                raise HTTPException(
                    status_code=400,
                    detail=f"í…œí”Œë¦¿ '{create_request.template_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿: {available_templates}"
                )
            service.apply_template(create_request.template_name)

        if create_request.vllm_config:
            logger.info("VLLM ì„¤ì • ì ìš©")
            for key, value in create_request.vllm_config.dict().items():
                # env_nameì„ í†µí•´ PersistentConfig ê°ì²´ ì°¾ê¸°
                env_name = f"VLLM_{key.upper()}" if not key.startswith('vllm_') else key.upper()

                # all_configsì—ì„œ env_nameìœ¼ë¡œ ì°¾ê¸°
                if hasattr(service.config, 'configs'):
                    for config_obj in service.config.configs.values():
                        if hasattr(config_obj, 'env_name') and config_obj.env_name == env_name:
                            config_obj.value = value
                            logger.info("VLLM ì„¤ì • ì ìš©: %s = %s", key, value)

        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance_id = service.create_vllm_instance(
            offer_id=create_request.offer_id,
            template_name=create_request.template_name
        )

        if not instance_id:
            raise HTTPException(status_code=400, detail="ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨")

        # ë°±ê·¸ë¼ìš´ë“œ ì„¤ì •
        background_tasks.add_task(service.wait_and_setup_instance, instance_id)

        return {
            "success": True,
            "instance_id": instance_id,
            "template_name": create_request.template_name,
            "message": "ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì •ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.",
            "status": "creating"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨")

@router.post("/instances/{instance_id}/setup-vllm",
    summary="VLLM ì„¤ì • ë° ì‹¤í–‰",
    description="ì¸ìŠ¤í„´ìŠ¤ì— VLLMì„ ì„¤ì •í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. requirements.txt ì„¤ì¹˜ë¶€í„° í™˜ê²½ë³€ìˆ˜ ì„¤ì •, ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ê¹Œì§€ ìë™í™”ë©ë‹ˆë‹¤.",
    response_model=Dict[str, Any])
async def setup_vllm(request: Request, instance_id: str, setup_request: SetupVLLMRequest):
    try:
        service = get_vast_service(request)
        results = []

        # 1. ë””ë ‰í† ë¦¬ í™•ì¸
        logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ í™•ì¸: {setup_request.script_directory}")
        check_result = service.vast_manager.execute_ssh_command(
            instance_id, f"ls -la {setup_request.script_directory}"
        )
        results.append({"step": "directory_check", "result": check_result})

        if not check_result.get("success"):
            return {
                "success": False,
                "error": f"ë””ë ‰í† ë¦¬ {setup_request.script_directory}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "results": results
            }

        # 2. requirements.txt ì„¤ì¹˜
        if setup_request.install_requirements:
            logger.info("ğŸ“¦ requirements.txt í™•ì¸ ë° ì„¤ì¹˜")
            req_check = service.vast_manager.execute_ssh_command(
                instance_id, f"ls {setup_request.script_directory}/requirements.txt 2>/dev/null || echo 'no requirements.txt'"
            )

            if "requirements.txt" in req_check.get("stdout", "") and "no requirements.txt" not in req_check.get("stdout", ""):
                install_result = service.vast_manager.execute_ssh_command(
                    instance_id, f"cd {setup_request.script_directory} && pip3 install -r requirements.txt"
                )
                results.append({"step": "install_requirements", "result": install_result})

        # 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • ë° ì‹¤í–‰
        env_vars = generate_vllm_env_vars(setup_request.vllm_config, setup_request.hf_token)
        if setup_request.additional_env_vars:
            env_vars.update(setup_request.additional_env_vars)

        env_exports = [f"export {key}={value}" for key, value in env_vars.items()]
        env_cmd = " && ".join(env_exports)

        main_py_cmd = f"""cd {setup_request.script_directory} && \\
{env_cmd} && \\
nohup python3 {setup_request.main_script} > {setup_request.log_file} 2>&1 &"""

        main_result = service.vast_manager.execute_ssh_command(instance_id, main_py_cmd)
        results.append({"step": "execute_main", "command": main_py_cmd, "result": main_result})

        # 4. í”„ë¡œì„¸ìŠ¤ í™•ì¸
        import time
        time.sleep(2)
        process_check = service.vast_manager.execute_ssh_command(
            instance_id, f"ps aux | grep {setup_request.main_script} | grep -v grep"
        )
        results.append({"step": "process_check", "result": process_check})

        return {
            "success": True,
            "instance_id": instance_id,
            "message": "VLLM ì„¤ì • ë° ì‹¤í–‰ ì™„ë£Œ",
            "config": {
                "script_directory": setup_request.script_directory,
                "main_script": setup_request.main_script,
                "log_file": setup_request.log_file,
                "environment_vars": env_vars
            },
            "results": results
        }

    except Exception as e:
        logger.error(f"VLLM ì„¤ì • ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="VLLM ì„¤ì • ì‹¤íŒ¨")

@router.post("/instances/{instance_id}/execute",
    summary="ëª…ë ¹ì–´ ì‹¤í–‰",
    description="ì¸ìŠ¤í„´ìŠ¤ì—ì„œ SSHë¥¼ í†µí•´ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ê³¼ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.",
    response_model=CommandExecutionResponse)
async def execute_command(request: Request, instance_id: str, command_request: ExecuteCommandRequest) -> CommandExecutionResponse:
    try:
        service = get_vast_service(request)

        # ëª…ë ¹ì–´ êµ¬ì„±
        commands = []
        if command_request.working_directory:
            commands.append(f"cd {command_request.working_directory}")

        if command_request.environment_vars:
            env_exports = [f"export {key}={value}" for key, value in command_request.environment_vars.items()]
            commands.extend(env_exports)

        commands.append(command_request.command)

        final_command = " && ".join(commands)
        if command_request.background:
            final_command = f"nohup bash -c '{final_command}' > /tmp/command_output.log 2>&1 &"

        result = service.vast_manager.execute_ssh_command(instance_id, final_command)

        return CommandExecutionResponse(
            success=result.get("success", False),
            instance_id=instance_id,
            command=command_request.command,
            stdout=result.get("stdout", ""),
            stderr=result.get("stderr", ""),
            background=command_request.background,
            error=result.get("error")
        )
    except Exception as e:
        logger.error(f"ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨")

@router.get("/instances",
    summary="ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ",
    description="ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ì˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. ìƒíƒœë³„ í•„í„°ë§ê³¼ ì •ë ¬ì„ ì§€ì›í•©ë‹ˆë‹¤.",
    response_model=InstanceListResponse)
async def list_instances(
    request: Request,
    status_filter: Optional[str] = Query(None, description="ìƒíƒœë³„ í•„í„°ë§"),
    include_destroyed: bool = Query(False, description="ì‚­ì œëœ ì¸ìŠ¤í„´ìŠ¤ í¬í•¨"),
    sort_by: str = Query("created_at", description="ì •ë ¬ ê¸°ì¤€")
) -> InstanceListResponse:
    try:
        service = get_vast_service(request)

        # VastAIì—ì„œ ë‚´ê°€ í˜„ì¬ ë¹Œë¦° ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ
        my_active_instance_ids = set()
        try:
            result = service.vast_manager.run_command(["vastai", "show", "instances"], parse_json=False)
            if result["success"]:
                vast_instances = service.vast_manager._parse_instances_from_text(result["data"])
                for vast_inst in vast_instances:
                    if isinstance(vast_inst, dict) and vast_inst.get("id"):
                        my_active_instance_ids.add(str(vast_inst["id"]))
        except Exception as e:
            logger.warning(f"VastAI ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")

        # DBì—ì„œ VastAIì— ì—†ëŠ” ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ deletedë¡œ ì—…ë°ì´íŠ¸
        updated_count = 0
        if service.db_manager:
            from service.database.models.vast import VastInstance
            db_instances = service.db_manager.find_all(VastInstance)

            for db_inst in db_instances:
                instance_id = str(db_inst.instance_id)
                if instance_id not in my_active_instance_ids and db_inst.status not in ["destroyed", "deleted"]:
                    logger.info(f"ì¸ìŠ¤í„´ìŠ¤ {instance_id}ê°€ ë‚´ ë¹Œë¦° ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ. ìƒíƒœë¥¼ deletedë¡œ ì—…ë°ì´íŠ¸")
                    try:
                        db_inst.status = "deleted"
                        service.db_manager.update(db_inst)
                        updated_count += 1
                    except Exception as e:
                        logger.error(f"ì¸ìŠ¤í„´ìŠ¤ {instance_id} ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

        # ë¡œê·¸ ì¶œë ¥
        if updated_count > 0:
            logger.info(f"ì´ {updated_count}ê°œ ì¸ìŠ¤í„´ìŠ¤ì˜ ìƒíƒœë¥¼ deletedë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤")

        # DBì—ì„œ deletedê°€ ì•„ë‹Œ ì¸ìŠ¤í„´ìŠ¤ë“¤ë§Œ ê°€ì ¸ì˜¤ê¸°
        instances = service.list_instances()

        # í•„í„°ë§
        if status_filter:
            instances = [inst for inst in instances
                        if inst.get("actual_status") == status_filter or
                           inst.get("status") == status_filter]

        if not include_destroyed:
            instances = [inst for inst in instances
                        if inst.get("actual_status") not in ["exited", "deleted"]]

        # ì •ë ¬
        if sort_by == "created_at":
            instances.sort(key=lambda x: x.get("created_at", ""), reverse=True)
        elif sort_by == "cost":
            instances.sort(key=lambda x: x.get("cost_per_hour", 0))

        return InstanceListResponse(instances=instances, total=len(instances))
    except Exception as e:
        logger.error(f"ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")

@router.get("/instances/{instance_id}",
    summary="ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ì¡°íšŒ",
    description="íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ì˜ ìƒì„¸ ìƒíƒœ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. DB ì •ë³´, vLLM ìƒíƒœ, ë¹„ìš© ì •ë³´ ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.",
    response_model=InstanceStatusResponse,
    responses={500: {"description": "ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨"}})
async def get_instance_status(request: Request, instance_id: str) -> InstanceStatusResponse:
    try:
        service = get_vast_service(request)
        enhanced_status = service.get_enhanced_instance_status(instance_id)

        return InstanceStatusResponse(
            instance_id=instance_id,
            status=enhanced_status.get("basic_status", {}).get("status", "unknown"),
            public_ip=enhanced_status.get("basic_status", {}).get("public_ip"),
            urls=enhanced_status.get("basic_status", {}).get("urls", {}),
            port_mappings=enhanced_status.get("basic_status", {}).get("port_mappings", {}),
            gpu_info=enhanced_status.get("db_info", {}).get("gpu_info"),
            cost_per_hour=enhanced_status.get("db_info", {}).get("cost_per_hour"),
            uptime=enhanced_status.get("db_info", {}).get("uptime"),
            vllm_status=enhanced_status.get("vllm_status")
        )
    except Exception as e:
        logger.error(f"ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨")

@router.delete("/instances/{instance_id}",
    summary="ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ",
    description="ì§€ì •ëœ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any],
    responses={
        400: {"description": "ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨"},
        500: {"description": "ì„œë²„ ì˜¤ë¥˜"}
    })
async def destroy_instance(request: Request, instance_id: str):
    try:
        service = get_vast_service(request)
        success = service.destroy_instance(instance_id)

        if not success:
            raise HTTPException(status_code=400, detail="ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨")

        return {
            "success": True,
            "message": f"ì¸ìŠ¤í„´ìŠ¤ {instance_id}ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤",
            "instance_id": instance_id
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨")

@router.get("/instances/{instance_id}/logs",
    summary="ë¡œê·¸ ì¡°íšŒ",
    description="ì¸ìŠ¤í„´ìŠ¤ì˜ ë¡œê·¸ íŒŒì¼ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any])
async def get_logs(request: Request, instance_id: str, log_file: str = "/tmp/vllm.log", lines: int = Query(50, ge=1, le=1000)):
    try:
        service = get_vast_service(request)

        # ë³´ì•ˆì„ ìœ„í•œ ê²½ë¡œ ì œí•œ
        allowed_paths = ["/tmp/", "/var/log/", "/vllm/vllm-script/"]
        if not any(log_file.startswith(path) for path in allowed_paths):
            log_file = f"/tmp/{log_file}"

        cmd = f"tail -{lines} {log_file} 2>/dev/null || echo 'Log file not found'"
        result = service.vast_manager.execute_ssh_command(instance_id, cmd)

        return {
            "instance_id": instance_id,
            "log_file": log_file,
            "lines_requested": lines,
            "content": result.get("stdout", ""),
            "error": result.get("stderr", ""),
            "success": result.get("success", False)
        }
    except Exception as e:
        logger.error(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨")

@router.get("/instances/{instance_id}/processes",
    summary="í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ì¡°íšŒ",
    description="ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any])
async def get_processes(request: Request, instance_id: str, process_name: Optional[str] = Query(None, description="íŠ¹ì • í”„ë¡œì„¸ìŠ¤ ì´ë¦„")):
    try:
        service = get_vast_service(request)

        if process_name:
            cmd = f"ps aux | grep {process_name} | grep -v grep"
        else:
            cmd = "ps aux | grep python | grep -v grep"

        result = service.vast_manager.execute_ssh_command(instance_id, cmd)

        processes = []
        if result.get("success") and result.get("stdout"):
            lines = result["stdout"].strip().split('\n')
            for line in lines:
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 11:
                        processes.append({
                            "user": parts[0],
                            "pid": parts[1],
                            "cpu": parts[2],
                            "mem": parts[3],
                            "command": " ".join(parts[10:])
                        })

        return {
            "instance_id": instance_id,
            "process_name": process_name,
            "processes": processes,
            "total_processes": len(processes)
        }
    except Exception as e:
        logger.error(f"í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨")
